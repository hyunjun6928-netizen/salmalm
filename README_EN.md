# ğŸ˜ˆ SalmAlm v0.11.1

[![Tests](https://github.com/hyunjun6928-netizen/salmalm/actions/workflows/test.yml/badge.svg)](https://github.com/hyunjun6928-netizen/salmalm/actions/workflows/test.yml)
[![PyPI](https://img.shields.io/pypi/v/salmalm)](https://pypi.org/project/salmalm/)
[![Python](https://img.shields.io/pypi/pyversions/salmalm)](https://pypi.org/project/salmalm/)
[![License](https://img.shields.io/github/license/hyunjun6928-netizen/salmalm)](LICENSE)

**Personal AI Gateway â€” Pure Python, Zero Dependencies**

> [ğŸ‡°ğŸ‡· í•œêµ­ì–´](README.md)

A self-hosted AI gateway built entirely on Python's standard library. No npm, no dependency hell, no Docker required. One command and you're running your own AI assistant with 32 tools.

The only optional dependency is `cryptography` for AES-256-GCM vault encryption. Without it, the vault falls back to HMAC-CTR (still secure, just not AEAD).

## ğŸš€ Quick Start

### pip (Recommended)

```bash
python -m pip install salmalm && python -m salmalm
```
Install â†’ server starts â†’ browser auto-opens â†’ `SalmAlm.bat` created on Desktop (double-click next time)

### .env File (Simple Config)

```bash
cp .env.example .env
# Edit .env â€” add your API keys
python -m salmalm
```

### Docker

```bash
docker run -p 18800:18800 -p 18801:18801 \
  -e SALMALM_VAULT_PW=changeme \
  -v salmalm_data:/app \
  $(docker build -q .)
```

### Docker Compose

```bash
git clone https://github.com/hyunjun6928-netizen/salmalm.git
cd salmalm
# Edit docker-compose.yml â€” set SALMALM_VAULT_PW and API keys
docker compose up -d
# â†’ http://localhost:18800
```

### Local LLM (Ollama â€” no API key needed)

```bash
ollama pull llama3.2
python -m salmalm
# In Settings, enter Ollama URL: http://localhost:11434/v1
# Use: /model ollama/llama3.2
```

## âœ¨ What It Does

Think of it as your own local ChatGPT, but with superpowers:

- **Talk to 27 LLMs** â€” Claude, GPT, Grok, Gemini, DeepSeek, Llama â€” through one interface
- **30 built-in tools** â€” run commands, edit files, search the web, manage cron jobs, control browsers
- **RAG search** â€” BM25 over your local files, no OpenAI embeddings needed
- **MCP support** â€” connect to Cursor, VS Code, or any MCP-compatible client
- **WebSocket** â€” real-time streaming via a from-scratch RFC 6455 implementation
- **Gateway-Node** â€” distribute tool execution across multiple machines
- **Telegram bot** â€” chat from your phone
- **Plugin system** â€” drop a `.py` file in `plugins/` and it just works
- **.env support** â€” configure API keys via `.env` file or encrypted vault
- **EN/KO i18n** â€” switch language in Settings (English default)
- **One-click update** â€” upgrade from Settings UI

## ğŸŒ Gateway-Node Architecture

Scale tool execution across multiple machines:

```bash
# Main server (gateway)
python -m salmalm

# Remote worker (node)
python -m salmalm --node --gateway-url http://gateway:18800
```

Nodes auto-register with the gateway. Tool calls are dispatched to remote nodes based on capabilities. Falls back to local execution on failure.

## ğŸ—ï¸ Architecture (25 Modules, ~10,400 lines)

```
salmalm/
â”œâ”€â”€ __init__.py         â€” logging setup
â”œâ”€â”€ __main__.py         â€” entry point + .env loader
â”œâ”€â”€ constants.py        â€” config, costs, model registry, thresholds
â”œâ”€â”€ crypto.py           â€” AES-256-GCM vault (HMAC-CTR fallback)
â”œâ”€â”€ core.py             â€” audit, cache, sessions, cron, routing
â”œâ”€â”€ agents.py           â€” SubAgent, SkillLoader, PluginLoader
â”œâ”€â”€ llm.py              â€” multi-provider LLM calls (6 providers + auto-fallback)
â”œâ”€â”€ tools.py            â€” 32 tool definitions
â”œâ”€â”€ tool_handlers.py    â€” tool execution + gateway dispatch
â”œâ”€â”€ prompt.py           â€” system prompt builder
â”œâ”€â”€ engine.py           â€” Intelligence Engine (classify â†’ plan â†’ execute â†’ reflect)
â”œâ”€â”€ templates.py        â€” HTML templates (Web UI)
â”œâ”€â”€ telegram.py         â€” async Telegram bot
â”œâ”€â”€ discord_bot.py      â€” Discord Gateway (raw WebSocket)
â”œâ”€â”€ web.py              â€” Web UI + REST API + SSE streaming + CSRF
â”œâ”€â”€ ws.py               â€” WebSocket server (RFC 6455)
â”œâ”€â”€ rag.py              â€” BM25 search engine (SQLite-backed)
â”œâ”€â”€ mcp.py              â€” Model Context Protocol server + client
â”œâ”€â”€ browser.py          â€” Chrome DevTools Protocol automation
â”œâ”€â”€ nodes.py            â€” Gateway-Node architecture (registry + remote dispatch)
â”œâ”€â”€ stability.py        â€” circuit breaker, health monitor, watchdog
â”œâ”€â”€ auth.py             â€” JWT auth, RBAC, rate limiter, PBKDF2
â”œâ”€â”€ tls.py              â€” self-signed TLS cert generation
â”œâ”€â”€ container.py        â€” lightweight DI container
â”œâ”€â”€ logging_ext.py      â€” JSON structured logging, rotation
â”œâ”€â”€ docs.py             â€” auto-generated API documentation
â””â”€â”€ plugins/            â€” Drop-in tool plugins
```

## ğŸ” Security

| Layer | Implementation |
|-------|---------------|
| **Vault** | AES-256-GCM (or HMAC-CTR fallback), PBKDF2 200K iterations |
| **Auth** | JWT tokens (HMAC-SHA256), API keys, PBKDF2 password hashing |
| **RBAC** | admin / user / readonly roles with permission matrix |
| **CORS** | Same-origin whitelist only (127.0.0.1, localhost) |
| **Rate Limit** | Token bucket per user + per IP, configurable per role |
| **Upload** | Filename sanitization, 50MB limit, path traversal prevention |
| **Exec** | Command blocklist + regex pattern matching + subprocess isolation |
| **Audit** | SHA-256 hash chain, tamper-evident log |

## ğŸ“¡ API

| Endpoint | Auth | Description |
|----------|------|-------------|
| `GET /api/status` | No | Version, usage stats |
| `GET /api/health` | No | Component health (8 checks) |
| `POST /api/auth/login` | No | Get JWT token |
| `POST /api/unlock` | No | Unlock vault |
| `POST /api/chat` | Yes | Send message |
| `POST /api/chat/stream` | Yes | SSE streaming response |
| `POST /api/vault` | Admin | Key CRUD |
| `GET /api/dashboard` | Yes | Sessions, costs, cron |
| `GET /api/rag/search?q=...` | Yes | BM25 search |
| `GET /api/nodes` | Yes | List connected nodes |
| `GET /docs` | No | Auto-generated API docs |
| `ws://127.0.0.1:18801` | â€” | WebSocket |

## ğŸ”‘ Supported Models

| Provider | Models |
|----------|--------|
| Anthropic | Claude Opus 4, Sonnet 4, Haiku 3.5 |
| OpenAI | GPT-5.3 Codex, GPT-4.1, o3, o4-mini |
| xAI | Grok-4, Grok-3, Grok-3 Mini |
| Google | Gemini 3 Pro/Flash, Gemini 2.5 Pro/Flash |
| DeepSeek | R1, Chat |
| Meta | Llama 4 Maverick, Scout |

All with per-model cost tracking (input + output tokens â†’ USD).

## ğŸ§  Intelligence Engine

Not just a chat proxy. Every message goes through:

1. **Intent Classification** â€” 7 tiers (trivial â†’ emergency) with keyword + length analysis
2. **Model Selection** â€” cheapest model that can handle the task
3. **Tool Planning** â€” which tools to call, in what order
4. **Parallel Execution** â€” independent tool calls run concurrently
5. **Self-Reflection** â€” checks output quality, retries if needed

## ğŸ“Š Stats

- ~10,400 lines of Python across 25 modules
- 30 built-in tools + plugin extensibility
- 27+ LLM models with cost tracking (including Ollama local models)
- 85 unit tests
- 21/21 self-test on startup
- 8-component health monitoring

## ğŸ“ v0.11.1 Changelog

- **ğŸ’¬ Multi-session UI**: sidebar chat list â€” create/switch/delete conversations, auto-titling
- **ğŸ“ˆ Dashboard**: `/dashboard` â€” Chart.js tool usage bar chart + model cost doughnut + stats table
- **ğŸ¤ STT (Speech-to-Text)**: Whisper API + mic button â€” record â†’ transcribe â†’ insert into input
- **ğŸ“± PWA**: manifest.json + service worker + app icon â€” install as home screen app
- **32 tools** (added `stt`)

### v0.11.0
- **ğŸ‘ï¸ `image_analyze` vision tool**: image analysis (URL/base64/local file/OCR)
- **ğŸ§  Prompt v0.5.0**: improved intent classification + tool selection accuracy
- **ğŸ“¡ SSE chunk streaming**: real-time response streaming with tool counters
- **ğŸ“‹ CI/CD**: GitHub Actions matrix (Ubuntu/macOS/Windows Ã— Python 3.10â€“3.13)
- **ğŸ“› Badges**: PyPI + CI + License + Python version
- **ğŸ“– CONTRIBUTING + CHANGELOG + FAQ (KR+EN) + use-cases (KR+EN) + issue templates**

### v0.10.9
- **ğŸ”’ P0 Security**: admin auth + loopback enforcement on sensitive endpoints
- **ğŸ”“ Setup Wizard**: first-run password setup/skip screen
- **ğŸ”‘ Password Management**: change/remove/set password anytime from Settings
- **â™¾ï¸ Unlimited tool loop**: no artificial cap (OpenClaw-style)

Full history: [CHANGELOG.md](CHANGELOG.md)

## ğŸ“œ License

MIT
