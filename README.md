<div align="center">

# üòà SalmAlm (ÏÇ∂Ïïé)

### Your Entire AI Life in One `pip install`

[![PyPI](https://img.shields.io/pypi/v/salmalm)](https://pypi.org/project/salmalm/)
[![Python](https://img.shields.io/badge/python-3.10%E2%80%933.14-blue)](https://pypi.org/project/salmalm/)
[![License: MIT](https://img.shields.io/badge/license-MIT-green)](LICENSE)
[![CI](https://github.com/hyunjun6928-netizen/salmalm/actions/workflows/ci.yml/badge.svg)](https://github.com/hyunjun6928-netizen/salmalm/actions)
[![Tests](https://img.shields.io/badge/tests-1%2C878%20passed-brightgreen)]()
[![Tools](https://img.shields.io/badge/tools-62-blueviolet)]()
[![Coverage](https://img.shields.io/badge/docstrings-99%25-blue)]()

**[ÌïúÍµ≠Ïñ¥ README](README_KR.md)** ¬∑ **[Documentation](https://hyunjun6928-netizen.github.io/salmalm/)**

</div>

---

## What is SalmAlm?

SalmAlm is a **personal AI gateway** ‚Äî one Python package that gives you a full-featured AI assistant with a web UI, Telegram/Discord bots, 62 tools, browser automation, sub-agents, and memory system.

No Docker. No Node.js. No config files. Just:

```bash
pip install salmalm
salmalm
# ‚Üí http://localhost:18800
```

First launch opens a **Setup Wizard** ‚Äî paste an API key, pick a model, done.

> ‚ö†Ô∏è **Don't run `salmalm` from inside a cloned repo directory** ‚Äî Python will import the local source instead of the installed package. Run from `~` or any other directory.

---

## Why SalmAlm?

| | Feature | SalmAlm | ChatGPT | OpenClaw | Open WebUI |
|---|---|:---:|:---:|:---:|:---:|
| üîß | Install complexity | `pip install` | N/A | npm + config | Docker |
| ü§ñ | Multi-provider routing | ‚úÖ Auto 3-tier | ‚ùå | ‚úÖ | ‚úÖ |
| üß† | Memory (2-layer + auto-recall) | ‚úÖ | ‚ùå | ‚úÖ | ‚ùå |
| ü§ñ | Sub-agents (spawn/steer/notify) | ‚úÖ | ‚ùå | ‚úÖ | ‚ùå |
| üåê | Browser automation (Playwright) | ‚úÖ | ‚ùå | ‚úÖ | ‚ùå |
| üß† | Extended Thinking (4 levels) | ‚úÖ | ‚ùå | ‚úÖ | ‚ùå |
| üîê | Encrypted Vault (AES-256-GCM) | ‚úÖ | ‚ùå | ‚ùå | ‚ùå |
| üì± | Telegram + Discord | ‚úÖ | ‚ùå | ‚úÖ | ‚ùå |
| üß© | MCP (Model Context Protocol) | ‚úÖ | ‚ùå | ‚ùå | ‚úÖ |
| ü¶ô | Local LLM (Ollama/LM Studio/vLLM) | ‚úÖ | ‚ùå | ‚úÖ | ‚úÖ |
| üì¶ | Zero dependencies* | ‚úÖ | N/A | ‚ùå | ‚ùå |
| üí∞ | Cost optimization (83% savings) | ‚úÖ | ‚ùå | ‚ùå | ‚ùå |

*\*stdlib-only core; optional `cryptography` for AES-256-GCM vault*

---

## ‚ö° Quick Start (5Î∂ÑÏù¥Î©¥ Ï∂©Î∂ÑÌï©ÎãàÎã§)

### Step 1: ÏÑ§Ïπò (30Ï¥à)
```bash
pip install salmalm
```

### Step 2: Ïã§Ìñâ (10Ï¥à)
```bash
salmalm --open
# ‚Üí Î∏åÎùºÏö∞Ï†ÄÍ∞Ä ÏûêÎèôÏúºÎ°ú Ïó¥Î¶ΩÎãàÎã§ (http://localhost:18800)

# ÎòêÎäî (editable installÏóêÏÑú console_scriptÍ∞Ä Ïïà Îê† Îïå):
python3 -m salmalm --open
```

### Step 3: API ÌÇ§ ÏûÖÎ†• (2Î∂Ñ)
1. Ïõπ UIÏùò **Setup Wizard**Í∞Ä ÏûêÎèôÏúºÎ°ú ÎúπÎãàÎã§
2. AI Ï†úÍ≥µÏÇ¨Ïùò API ÌÇ§Î•º Î∂ôÏó¨ÎÑ£Í∏∞ ÌïòÏÑ∏Ïöî:
   - [Anthropic Console](https://console.anthropic.com/) ‚Üí API Keys
   - [OpenAI Platform](https://platform.openai.com/api-keys) ‚Üí API Keys
   - ÎòêÎäî [Google AI Studio](https://aistudio.google.com/apikey) ‚Üí API Keys
3. "Save" ÌÅ¥Î¶≠ ‚Üí ÎÅù!

### Step 4: ÎåÄÌôî ÏãúÏûë (Î∞îÎ°ú!)
```
"Ïò§Îäò ÎÇ†Ïî® Ïñ¥Îïå?"          ‚Üí Ïõπ Í≤ÄÏÉâ + ÎãµÎ≥Ä
"Ïù¥ ÏΩîÎìú Î¶¨Î∑∞Ìï¥Ï§ò"         ‚Üí ÌååÏùº ÏùΩÍ∏∞ + Î∂ÑÏÑù
"/model sonnet"            ‚Üí Î™®Îç∏ Î≥ÄÍ≤Ω
"/help"                    ‚Üí Ï†ÑÏ≤¥ Î™ÖÎ†πÏñ¥ Î≥¥Í∏∞
```

> üí° **ÏûêÏó∞Ïñ¥Î°ú ÎßêÌïòÎ©¥ Îê©ÎãàÎã§.** 62Í∞ú ÎèÑÍµ¨Î•º AIÍ∞Ä ÏïåÏïÑÏÑú ÏÑ†ÌÉùÌï©ÎãàÎã§.
> Î™ÖÎ†πÏñ¥Î•º Ïô∏Ïö∏ ÌïÑÏöî ÏóÜÏù¥, ÌïòÍ≥† Ïã∂ÏùÄ Í±∏ Í∑∏ÎÉ• ÎßêÌïòÏÑ∏Ïöî.

### Í≥†Í∏â ÏòµÏÖò
```bash
salmalm --shortcut          # Î∞îÌÉïÌôîÎ©¥ Î∞îÎ°úÍ∞ÄÍ∏∞ ÏÉùÏÑ±
salmalm doctor              # ÏûêÍ∞ÄÏßÑÎã®
salmalm --update            # ÏûêÎèô ÏóÖÎç∞Ïù¥Ìä∏
SALMALM_PORT=8080 salmalm   # Ìè¨Ìä∏ Î≥ÄÍ≤Ω
```

### Supported Providers (Auto-Routing)

| Provider | Models | Tier |
|---|---|---|
| Anthropic | Claude Opus 4.6, Sonnet 4.6, Haiku 4.5 | Complex / Moderate / Simple |
| OpenAI | GPT-5.2, GPT-5, o4-mini | Complex / Moderate |
| Google | Gemini 3.1 Pro, 2.5 Flash | Moderate / Simple |
| xAI | Grok-4, Grok-3-mini | Complex / Simple |
| DeepSeek | R1, Chat | Via OpenRouter |
| **Local LLM** | Ollama / LM Studio / vLLM | Auto-detected |

---

## üß† Architecture

```
Browser ‚îÄ‚îÄWebSocket‚îÄ‚îÄ‚ñ∫ SalmAlm ‚îÄ‚îÄ‚ñ∫ Anthropic / OpenAI / Google / xAI / Local
   ‚îÇ                     ‚îÇ
   ‚îî‚îÄ‚îÄHTTP/SSE‚îÄ‚îÄ‚ñ∫       ‚îú‚îÄ‚îÄ Smart Model Router (3-tier: simple/moderate/complex)
                         ‚îú‚îÄ‚îÄ Engine Pipeline (classify ‚Üí route ‚Üí context ‚Üí execute)
Telegram ‚îÄ‚îÄ‚ñ∫             ‚îú‚îÄ‚îÄ Memory System (2-layer + auto-recall + TF-IDF RAG)
Discord  ‚îÄ‚îÄ‚ñ∫             ‚îú‚îÄ‚îÄ Sub-Agent Manager (spawn/steer/kill/notify)
                         ‚îú‚îÄ‚îÄ Tool Registry (62 tools, risk-tiered)
                         ‚îú‚îÄ‚îÄ Browser Automation (Playwright subprocess)
                         ‚îú‚îÄ‚îÄ Security Middleware (auth/CSRF/CSP/rate-limit/audit)
                         ‚îú‚îÄ‚îÄ Vault (PBKDF2-200K + AES-256-GCM)
                         ‚îî‚îÄ‚îÄ Cron / Backup / Self-Diagnostics
```

### Codebase Metrics

| Metric | Value |
|---|---|
| Python files | 192 |
| Total lines | ~52,450 |
| Functions | ~1,800 |
| Max cyclomatic complexity | 20 (all functions) |
| Largest file | 778 lines |
| Files > 800 lines | 0 |
| Docstring coverage | 99% |
| Return type hints | 81% |
| Tests | 1,878 passing |

---

## üéØ Feature Overview

### Core AI Engine
- **3-tier auto-routing** ‚Äî simple‚ÜíHaiku ($1/M), moderate‚ÜíSonnet ($3/M), complex‚ÜíGPT-5.2/Sonnet ($2-3/M)
- **Extended Thinking** ‚Äî 4 levels (low/medium/high/xhigh) with budget control
- **Cross-provider message sanitization** ‚Äî seamless model switching mid-conversation
- **5-stage context compaction** ‚Äî strip binary ‚Üí trim tools ‚Üí drop old ‚Üí truncate ‚Üí LLM summarize
- **Prompt caching** ‚Äî Anthropic cache_control for 90% cost reduction
- **Model failover** ‚Äî exponential backoff + retry across providers
- **Infinite loop detection** ‚Äî 3+ same (tool, args_hash) in last 6 iterations = auto-break

### Memory System (OpenClaw-style)
- **2-layer architecture** ‚Äî `MEMORY.md` (curated long-term) + `memory/YYYY-MM-DD.md` (daily logs)
- **Auto-recall** ‚Äî searches memory before each response, injects relevant context
- **Auto-curation** ‚Äî promotes important daily entries to long-term memory
- **TF-IDF + cosine similarity search** across all memory files
- **Memory scrubbing** ‚Äî API keys/secrets auto-redacted before storage

### Sub-Agent System
- **Spawn** background AI workers with independent sessions
- **Thinking level** per agent (low/medium/high/xhigh)
- **Labels** for human-readable naming
- **Steer** running agents with mid-task guidance
- **Auto-notify** on completion (WebSocket + Telegram push)
- **Collect** results (push-style, like OpenClaw)

```
/subagents spawn Review this PR --model sonnet --thinking high --label pr-review
/subagents list
/subagents steer abc123 Focus on security issues
/subagents kill abc123
/subagents collect
```

### 62 Built-in Tools
Web search (Brave), email (Gmail), calendar (Google), file I/O, shell exec, Python eval (opt-in), image generation (DALL-E/Aurora), TTS/STT, **browser automation (Playwright)**, RAG search, QR codes, system monitor, OS-native sandbox, mesh networking, and more.

### Web UI
- Real-time streaming (SSE-first, WebSocket for typing indicators)
- Embedding RAG ‚Äî hybrid vector search (OpenAI/Google embeddings + BM25 fallback)
- Agent steer ‚Äî `/agent steer <label> <message>` to control running sub-agents
- Browser aria-ref compression ‚Äî 10x token savings for browser automation
- Thinking stream UI ‚Äî real-time collapsible thinking display
- Session branching, rollback, search (`Ctrl+K`), command palette (`Ctrl+Shift+P`)
- Dark/Light themes, **EN/KR i18n**
- Image paste/drag-drop with vision, code syntax highlighting
- Settings panels: Engine, Routing, Telegram, Discord, Memory, Cron, Backup
- PWA installable

### Channels
- **Web** ‚Äî full SPA at `localhost:18800`
- **Telegram** ‚Äî polling + webhook with inline buttons
- **Discord** ‚Äî bot with thread support and mentions

---

## ‚ú® Unique Features

| Feature | What it does |
|---|---|
| **Self-Evolving Prompt** | AI auto-generates personality rules from conversations |
| **Dead Man's Switch** | Emergency actions if you go inactive for N days |
| **Shadow Mode** | AI learns your style, replies as you when away |
| **Life Dashboard** | Unified health, finance, habits, calendar view |
| **Mood-Aware Response** | Detects emotional state, adjusts tone |
| **A/B Split Response** | Two model perspectives on the same question |
| **Time Capsule** | Schedule messages to your future self |
| **Thought Stream** | Private journaling with hashtag search and mood tracking |

---

## üí∞ Cost Optimization

SalmAlm is designed to minimize API costs without sacrificing quality:

| Feature | Effect |
|---|---|
| Dynamic tool loading | 62 tools ‚Üí 0 (chat) or 7-12 (actions) per request |
| 3-tier auto-routing | Simple‚Üí$1/M, Moderate‚Üí$3/M, Complex‚Üí$3/M (no Opus needed) |
| Tool schema compression | 7,749 ‚Üí 693 tokens (91% reduction) |
| System prompt compression | 762 ‚Üí 310 tokens |
| Intent-based max_tokens | Chat 512, search 1024, code 4096 |
| Intent-based history trim | Chat 10 turns, code 20 turns |
| Cache TTL | Same question cached (30min‚Äì24h, configurable) |
| Cross-provider failover | Falls back to cheaper model on rate limit |

**Result: $7.09/day ‚Üí $1.23/day (83% savings at 100 calls/day)**

---

## üîí Security

**Dangerous features default OFF** ‚Äî everything requires explicit opt-in:

| Feature | Default | Opt-in |
|---|---|---|
| Network bind | `127.0.0.1` | `SALMALM_BIND=0.0.0.0` |
| Shell operators | Blocked | `SALMALM_ALLOW_SHELL=1` |
| Python eval | **Disabled** | `SALMALM_PYTHON_EVAL=1` |
| Home dir file read | Workspace only | `SALMALM_ALLOW_HOME_READ=1` |
| Plugin system | Disabled | `SALMALM_PLUGINS=1` |

### Security Hardening
- **SSRF defense** ‚Äî DNS pinning + private IP block on every redirect hop
- **Tool risk tiers** ‚Äî Critical tools blocked on external bind without auth
- **CSRF** ‚Äî Origin validation + `X-Requested-With` header
- **CSP** ‚Äî Strict nonce mode available
- **Audit log** ‚Äî secrets scrubbed before logging (9 pattern types)
- **Memory scrubbing** ‚Äî API keys auto-redacted before storage
- **Path validation** ‚Äî `Path.is_relative_to()` for all file operations
- **Session isolation** ‚Äî user_id scoped, export restricted to own data
- **Node dispatch** ‚Äî HMAC-SHA256 signed payloads
- **150+ security regression tests** in CI

See [`SECURITY.md`](SECURITY.md) for full threat model.

---

## ü¶ô Local LLM Setup

| Server | Endpoint | Setup |
|---|---|---|
| **Ollama** | `http://localhost:11434/v1` | `ollama serve` |
| **LM Studio** | `http://localhost:1234/v1` | Start server in LM Studio |
| **vLLM** | `http://localhost:8000/v1` | `vllm serve <model>` |

Settings ‚Üí **Local LLM** ‚Üí paste endpoint ‚Üí Save. Models auto-discovered.

---

## üîß Configuration

```bash
# Server
SALMALM_PORT=18800         # Web server port
SALMALM_BIND=127.0.0.1    # Bind address
SALMALM_HOME=~/SalmAlm    # Data directory

# AI
SALMALM_PLANNING=1         # Planning phase (opt-in)
SALMALM_REFLECT=1          # Reflection pass (opt-in)
SALMALM_MAX_TOOL_ITER=25   # Max tool iterations
SALMALM_COST_CAP=0         # Daily cost cap (0=unlimited)

# Security
SALMALM_PYTHON_EVAL=1       # Enable python_eval tool
SALMALM_PLUGINS=1           # Enable plugin system
SALMALM_ALLOW_SHELL=1       # Enable shell operators
```

All settings also available in **Web UI ‚Üí Settings**.

---

## ü§ù Contributing

```bash
git clone https://github.com/hyunjun6928-netizen/salmalm.git
cd salmalm
pip install -e ".[dev]"
python -m pytest tests/ -q --timeout=30 -x \
  --ignore=tests/test_multi_tenant.py \
  --ignore=tests/test_fresh_install_e2e.py
```

See [`CONTRIBUTING.md`](CONTRIBUTING.md).

---

## üìÑ License

[MIT](LICENSE)

---

<div align="center">

**SalmAlm** = ÏÇ∂(Life) + Ïïé(Knowledge)

*Your life, understood by AI.*

</div>
