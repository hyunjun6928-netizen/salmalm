"""SalmAlm Self-Evolving Prompt â€” learns user preferences from conversation patterns."""

from __future__ import annotations

import json
import os
import re
import time
from collections import Counter
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

from .constants import KST

EVOLUTION_DIR = Path.home() / '.salmalm'
EVOLUTION_FILE = EVOLUTION_DIR / 'evolution.json'
EVOLUTION_HISTORY_FILE = EVOLUTION_DIR / 'evolution_history.json'

# How many conversations between auto-evolution suggestions
EVOLVE_INTERVAL = 20
MAX_AUTO_RULES = 20


def _ensure_dir():
    EVOLUTION_DIR.mkdir(parents=True, exist_ok=True)


# â”€â”€ Korean character detection â”€â”€
_KR_RE = re.compile(r'[\uac00-\ud7af\u3130-\u318f]')
_EN_RE = re.compile(r'[a-zA-Z]')

# â”€â”€ Topic keywords â”€â”€
_TOPIC_KEYWORDS = {
    'coding': ['ì½”ë“œ', 'code', 'python', 'javascript', 'function', 'class', 'bug', 'error',
               'debug', 'í•¨ìˆ˜', 'ë³€ìˆ˜', 'variable', 'api', 'git', 'deploy', 'ë°°í¬'],
    'writing': ['ê¸€', 'write', 'essay', 'ì‘ë¬¸', 'ë¬¸ì¥', 'blog', 'ë¸”ë¡œê·¸', 'article', 'ê¸°ì‚¬'],
    'math': ['ìˆ˜í•™', 'math', 'calculate', 'ê³„ì‚°', 'equation', 'ë°©ì •ì‹', 'formula'],
    'language': ['ë²ˆì—­', 'translate', 'grammar', 'ë¬¸ë²•', 'english', 'ì˜ì–´', 'í•œêµ­ì–´'],
    'work': ['ì—…ë¬´', 'work', 'meeting', 'íšŒì˜', 'project', 'í”„ë¡œì íŠ¸', 'deadline', 'ë§ˆê°'],
    'personal': ['ê¸°ë¶„', 'feel', 'ê°ì •', 'mood', 'ì¼ìƒ', 'daily', 'life', 'ìƒí™œ'],
    'learning': ['ë°°ìš°', 'learn', 'study', 'ê³µë¶€', 'tutorial', 'ê°•ì˜', 'course'],
    'system': ['ì„œë²„', 'server', 'docker', 'linux', 'ssh', 'deploy', 'infra', 'ì¸í”„ë¼'],
}

# â”€â”€ Feedback signals â”€â”€
_POSITIVE_SIGNALS = ['ê³ ë§ˆì›Œ', 'ê°ì‚¬', 'thanks', 'thank', 'perfect', 'ì™„ë²½', 'great', 'ì¢‹ì•„',
                     'í›Œë¥­', 'awesome', 'nice', 'ì˜í–ˆ', 'good', 'ë§ì•„', 'exactly', 'ì •í™•']
_NEGATIVE_SIGNALS = ['ì•„ë‹ˆ', 'no', 'wrong', 'í‹€ë ¸', 'ì˜ëª»', 'bad', 'ë³„ë¡œ', 'ë„ˆë¬´ ê¸¸',
                     'too long', 'too short', 'ì§§ê²Œ', 'ê¸¸ê²Œ', 'ë‹¤ì‹œ', 'again', 'retry',
                     'ì´í•´ ëª»', "don't understand", 'ë³µì¡', 'complicated']


class PatternAnalyzer:
    """Analyzes conversation patterns using pure Python heuristics."""

    @staticmethod
    def analyze_length_preference(messages: List[Dict]) -> str:
        """Analyze if user prefers concise or detailed responses.
        
        Looks at user message lengths and feedback signals about length.
        Returns 'concise', 'detailed', or 'mixed'.
        """
        if not messages:
            return 'mixed'

        user_msgs = [m for m in messages if m.get('role') == 'user']
        if not user_msgs:
            return 'mixed'

        lengths = []
        for m in user_msgs:
            content = m.get('content', '')
            if isinstance(content, list):
                content = ' '.join(b.get('text', '') for b in content if isinstance(b, dict))
            lengths.append(len(str(content)))

        avg_len = sum(lengths) / len(lengths) if lengths else 0

        # Check for explicit length feedback
        short_signals = 0
        long_signals = 0
        for m in user_msgs:
            text = str(m.get('content', '')).lower()
            if any(s in text for s in ['ì§§ê²Œ', 'short', 'brief', 'ê°„ë‹¨íˆ', 'concise', 'ìš”ì•½']):
                short_signals += 1
            if any(s in text for s in ['ìì„¸íˆ', 'detail', 'elaborate', 'ê¸¸ê²Œ', 'explain more', 'ë” ì„¤ëª…']):
                long_signals += 1

        if short_signals > long_signals and short_signals >= 2:
            return 'concise'
        if long_signals > short_signals and long_signals >= 2:
            return 'detailed'
        if avg_len < 30:
            return 'concise'
        if avg_len > 150:
            return 'detailed'
        return 'mixed'

    @staticmethod
    def analyze_time_patterns(messages: List[Dict]) -> Dict[str, str]:
        """Analyze conversation tone by time of day.
        
        Returns dict like {hour_range: mood_tendency}.
        """
        time_moods: Dict[str, List[str]] = {
            'dawn': [],      # 0-6
            'morning': [],   # 7-11
            'afternoon': [], # 12-17
            'evening': [],   # 18-23
        }

        for m in messages:
            ts = m.get('timestamp')
            if not ts:
                continue
            try:
                if isinstance(ts, (int, float)):
                    dt = datetime.fromtimestamp(ts, tz=KST)
                else:
                    dt = datetime.fromisoformat(str(ts))
                h = dt.hour
                text = str(m.get('content', '')).lower()

                if h < 7:
                    period = 'dawn'
                elif h < 12:
                    period = 'morning'
                elif h < 18:
                    period = 'afternoon'
                else:
                    period = 'evening'

                # Simple mood heuristic
                emotional_words = ['ã… ', 'í˜ë“¤', 'tired', 'sad', 'ê°ì„±', 'ê·¸ë¦¬ì›Œ']
                work_words = ['ì½”ë“œ', 'code', 'bug', 'ì—…ë¬´', 'work', 'deploy', 'ì„œë²„']
                if any(w in text for w in emotional_words):
                    time_moods[period].append('emotional')
                elif any(w in text for w in work_words):
                    time_moods[period].append('business')
                else:
                    time_moods[period].append('neutral')
            except (ValueError, TypeError, OSError):
                continue

        result = {}
        for period, moods in time_moods.items():
            if moods:
                c = Counter(moods)
                result[period] = c.most_common(1)[0][0]
        return result

    @staticmethod
    def analyze_topic_frequency(messages: List[Dict]) -> Counter:
        """Count topic categories from messages."""
        topic_counts: Counter = Counter()
        for m in messages:
            if m.get('role') != 'user':
                continue
            text = str(m.get('content', '')).lower()
            for topic, keywords in _TOPIC_KEYWORDS.items():
                if any(kw in text for kw in keywords):
                    topic_counts[topic] += 1
        return topic_counts

    @staticmethod
    def analyze_language_ratio(messages: List[Dict]) -> float:
        """Analyze Korean vs English ratio. 0.0=all EN, 1.0=all KR."""
        kr_chars = 0
        en_chars = 0
        for m in messages:
            if m.get('role') != 'user':
                continue
            text = str(m.get('content', ''))
            kr_chars += len(_KR_RE.findall(text))
            en_chars += len(_EN_RE.findall(text))

        total = kr_chars + en_chars
        if total == 0:
            return 0.5
        return kr_chars / total

    @staticmethod
    def analyze_feedback_signals(messages: List[Dict]) -> Dict[str, int]:
        """Detect positive/negative feedback patterns."""
        positive = 0
        negative = 0
        for m in messages:
            if m.get('role') != 'user':
                continue
            text = str(m.get('content', '')).lower()
            if any(s in text for s in _POSITIVE_SIGNALS):
                positive += 1
            if any(s in text for s in _NEGATIVE_SIGNALS):
                negative += 1
        return {'positive': positive, 'negative': negative}

    @staticmethod
    def analyze_code_comment_preference(messages: List[Dict]) -> Optional[str]:
        """Detect if user prefers or dislikes code comments.
        
        Returns 'prefer', 'dislike', or None.
        """
        prefer = 0
        dislike = 0
        for m in messages:
            if m.get('role') != 'user':
                continue
            text = str(m.get('content', '')).lower()
            if any(s in text for s in ['ì£¼ì„ ë„£', 'ì£¼ì„ ì¶”ê°€', 'add comment', 'with comment', 'ì£¼ì„ í¬í•¨']):
                prefer += 1
            if any(s in text for s in ['ì£¼ì„ ë¹¼', 'ì£¼ì„ ì—†ì´', 'no comment', 'without comment', 'ì£¼ì„ ì œê±°']):
                dislike += 1
        if prefer > dislike and prefer >= 2:
            return 'prefer'
        if dislike > prefer and dislike >= 2:
            return 'dislike'
        return None


class PromptEvolver:
    """Learns user preferences and evolves the system prompt over time."""

    def __init__(self):
        _ensure_dir()
        self.analyzer = PatternAnalyzer()
        self.state = self._load_state()

    def _load_state(self) -> Dict[str, Any]:
        if EVOLUTION_FILE.exists():
            try:
                return json.loads(EVOLUTION_FILE.read_text(encoding='utf-8'))
            except (json.JSONDecodeError, OSError):
                pass
        return {
            'conversation_count': 0,
            'preferences': {},
            'auto_rules': [],
            'last_analysis': None,
            'created_at': datetime.now(KST).isoformat(),
        }

    def _save_state(self):
        _ensure_dir()
        EVOLUTION_FILE.write_text(json.dumps(self.state, ensure_ascii=False, indent=2),
                                   encoding='utf-8')

    def record_conversation(self, messages: List[Dict]):
        """Record a conversation for pattern analysis."""
        self.state['conversation_count'] = self.state.get('conversation_count', 0) + 1
        self._analyze_and_update(messages)
        self._save_state()

    def _analyze_and_update(self, messages: List[Dict]):
        """Run pattern analysis and update preferences."""
        prefs = self.state.get('preferences', {})

        prefs['length_preference'] = self.analyzer.analyze_length_preference(messages)
        prefs['time_patterns'] = self.analyzer.analyze_time_patterns(messages)

        topics = self.analyzer.analyze_topic_frequency(messages)
        # Merge with existing
        existing_topics = prefs.get('topic_frequency', {})
        for topic, count in topics.items():
            existing_topics[topic] = existing_topics.get(topic, 0) + count
        prefs['topic_frequency'] = existing_topics

        prefs['language_ratio'] = self.analyzer.analyze_language_ratio(messages)
        
        feedback = self.analyzer.analyze_feedback_signals(messages)
        existing_fb = prefs.get('feedback', {'positive': 0, 'negative': 0})
        prefs['feedback'] = {
            'positive': existing_fb.get('positive', 0) + feedback['positive'],
            'negative': existing_fb.get('negative', 0) + feedback['negative'],
        }

        comment_pref = self.analyzer.analyze_code_comment_preference(messages)
        if comment_pref:
            prefs['code_comments'] = comment_pref

        self.state['preferences'] = prefs
        self.state['last_analysis'] = datetime.now(KST).isoformat()

    def should_suggest_evolution(self) -> bool:
        """Check if we should suggest evolving SOUL.md."""
        count = self.state.get('conversation_count', 0)
        return count > 0 and count % EVOLVE_INTERVAL == 0

    def generate_rules(self) -> List[str]:
        """Generate auto-evolution rules from learned preferences."""
        prefs = self.state.get('preferences', {})
        rules = []

        lp = prefs.get('length_preference')
        if lp == 'concise':
            rules.append('ì‚¬ìš©ìëŠ” ê°„ê²°í•œ ì‘ë‹µì„ ì„ í˜¸í•¨')
        elif lp == 'detailed':
            rules.append('ì‚¬ìš©ìëŠ” ìƒì„¸í•œ ì‘ë‹µì„ ì„ í˜¸í•¨')

        cp = prefs.get('code_comments')
        if cp == 'prefer':
            rules.append('ì‚¬ìš©ìëŠ” ì½”ë“œì— ì£¼ì„ì„ ì„ í˜¸í•¨')
        elif cp == 'dislike':
            rules.append('ì‚¬ìš©ìëŠ” ì½”ë“œ ì£¼ì„ì„ ì„ í˜¸í•˜ì§€ ì•ŠìŒ')

        lr = prefs.get('language_ratio', 0.5)
        if lr > 0.8:
            rules.append('ì‚¬ìš©ìëŠ” ì£¼ë¡œ í•œêµ­ì–´ë¡œ ì†Œí†µí•¨ â€” í•œêµ­ì–´ë¡œ ì‘ë‹µí•  ê²ƒ')
        elif lr < 0.2:
            rules.append('ì‚¬ìš©ìëŠ” ì£¼ë¡œ ì˜ì–´ë¡œ ì†Œí†µí•¨ â€” ì˜ì–´ë¡œ ì‘ë‹µí•  ê²ƒ')

        topics = prefs.get('topic_frequency', {})
        if topics:
            top = sorted(topics.items(), key=lambda x: x[1], reverse=True)[:3]
            for topic, count in top:
                if count >= 5:
                    rules.append(f'ì‚¬ìš©ìê°€ ìì£¼ ë¬»ëŠ” ì£¼ì œ: {topic}')

        tp = prefs.get('time_patterns', {})
        if tp.get('dawn') == 'emotional':
            rules.append('ìƒˆë²½ ì‹œê°„ëŒ€ì—ëŠ” ê°ì„±ì ì¸ í†¤ìœ¼ë¡œ ì‘ë‹µí•  ê²ƒ')
        if tp.get('afternoon') == 'business':
            rules.append('ì˜¤í›„ ì‹œê°„ëŒ€ì—ëŠ” ì—…ë¬´ì ì¸ í†¤ìœ¼ë¡œ ì‘ë‹µí•  ê²ƒ')

        return rules

    def apply_to_soul(self, soul_path: Path) -> str:
        """Apply auto-evolved rules to SOUL.md. Returns status message."""
        rules = self.generate_rules()
        if not rules:
            return 'ğŸ“Š ì•„ì§ ì¶©ë¶„í•œ íŒ¨í„´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'

        today = datetime.now(KST).strftime('%Y-%m-%d')

        # Read existing SOUL.md
        content = ''
        if soul_path.exists():
            content = soul_path.read_text(encoding='utf-8')

        # Remove old auto-evolved section
        content = re.sub(
            r'\n*<!-- auto-evolved-begin -->.*?<!-- auto-evolved-end -->\n*',
            '\n', content, flags=re.DOTALL
        )

        # Build new section
        rule_lines = []
        for r in rules[:MAX_AUTO_RULES]:
            rule_lines.append(f'<!-- auto-evolved: {today} -->\n- {r}')

        section = (
            '\n\n<!-- auto-evolved-begin -->\n'
            '## ğŸ§¬ Auto-Evolved Rules\n'
            + '\n'.join(rule_lines) +
            '\n<!-- auto-evolved-end -->\n'
        )

        content = content.rstrip() + section

        soul_path.parent.mkdir(parents=True, exist_ok=True)
        soul_path.write_text(content, encoding='utf-8')

        # Record history
        self._record_history(rules)

        self.state['auto_rules'] = rules[:MAX_AUTO_RULES]
        self._save_state()

        return f'âœ… {len(rules)}ê°œ ê·œì¹™ì´ SOUL.mdì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.'

    def _record_history(self, rules: List[str]):
        history = []
        if EVOLUTION_HISTORY_FILE.exists():
            try:
                history = json.loads(EVOLUTION_HISTORY_FILE.read_text(encoding='utf-8'))
            except (json.JSONDecodeError, OSError):
                pass
        history.append({
            'timestamp': datetime.now(KST).isoformat(),
            'rules': rules,
            'conversation_count': self.state.get('conversation_count', 0),
        })
        # Keep last 100 entries
        history = history[-100:]
        EVOLUTION_HISTORY_FILE.write_text(
            json.dumps(history, ensure_ascii=False, indent=2), encoding='utf-8')

    def get_status(self) -> str:
        """Return current evolution status."""
        prefs = self.state.get('preferences', {})
        count = self.state.get('conversation_count', 0)
        last = self.state.get('last_analysis', 'ì—†ìŒ')

        lines = [
            'ğŸ§¬ **Self-Evolving Prompt Status**',
            f'ğŸ“Š ë¶„ì„ëœ ëŒ€í™”: {count}íšŒ',
            f'ğŸ• ë§ˆì§€ë§‰ ë¶„ì„: {last}',
            '',
            '**í•™ìŠµëœ ì„ í˜¸ë„:**',
        ]

        lp = prefs.get('length_preference', 'ë¯¸ê°ì§€')
        lines.append(f'â€¢ ì‘ë‹µ ê¸¸ì´: {lp}')

        lr = prefs.get('language_ratio')
        if lr is not None:
            kr_pct = int(lr * 100)
            lines.append(f'â€¢ ì–¸ì–´ ë¹„ìœ¨: í•œêµ­ì–´ {kr_pct}% / ì˜ì–´ {100 - kr_pct}%')

        cp = prefs.get('code_comments', 'ë¯¸ê°ì§€')
        lines.append(f'â€¢ ì½”ë“œ ì£¼ì„: {cp}')

        topics = prefs.get('topic_frequency', {})
        if topics:
            top3 = sorted(topics.items(), key=lambda x: x[1], reverse=True)[:3]
            topic_str = ', '.join(f'{t}({c})' for t, c in top3)
            lines.append(f'â€¢ ì£¼ìš” ì£¼ì œ: {topic_str}')

        fb = prefs.get('feedback', {})
        if fb:
            lines.append(f'â€¢ í”¼ë“œë°±: ğŸ‘{fb.get("positive", 0)} / ğŸ‘{fb.get("negative", 0)}')

        rules = self.state.get('auto_rules', [])
        if rules:
            lines.append(f'\n**ìë™ ê·œì¹™** ({len(rules)}ê°œ):')
            for r in rules:
                lines.append(f'  - {r}')

        next_evolve = EVOLVE_INTERVAL - (count % EVOLVE_INTERVAL)
        lines.append(f'\nğŸ“ˆ ë‹¤ìŒ ì§„í™” ì œì•ˆê¹Œì§€: {next_evolve}íšŒ ëŒ€í™”')

        return '\n'.join(lines)

    def get_history(self) -> str:
        """Return evolution history."""
        if not EVOLUTION_HISTORY_FILE.exists():
            return 'ğŸ“œ ì§„í™” ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.'

        try:
            history = json.loads(EVOLUTION_HISTORY_FILE.read_text(encoding='utf-8'))
        except (json.JSONDecodeError, OSError):
            return 'ğŸ“œ ì§„í™” ì´ë ¥ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'

        if not history:
            return 'ğŸ“œ ì§„í™” ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.'

        lines = ['ğŸ“œ **Evolution History**\n']
        for entry in history[-10:]:
            ts = entry.get('timestamp', '?')
            count = entry.get('conversation_count', '?')
            rules = entry.get('rules', [])
            lines.append(f'**{ts}** (ëŒ€í™” {count}íšŒ)')
            for r in rules:
                lines.append(f'  - {r}')
            lines.append('')

        return '\n'.join(lines)

    def reset(self) -> str:
        """Reset all evolution data."""
        self.state = {
            'conversation_count': 0,
            'preferences': {},
            'auto_rules': [],
            'last_analysis': None,
            'created_at': datetime.now(KST).isoformat(),
        }
        self._save_state()
        return 'ğŸ”„ ì§„í™” ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.'


# Singleton
prompt_evolver = PromptEvolver()
