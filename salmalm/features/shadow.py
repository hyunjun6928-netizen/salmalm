"""SalmAlm Shadow Mode â€” learn user style and proxy-reply when absent."""

from __future__ import annotations

import json
import os
import re
import time
from collections import Counter
from pathlib import Path
from typing import Any, Dict, List, Optional

from salmalm.crypto import log

_PROFILE_DIR = Path.home() / ".salmalm"
_PROFILE_PATH = _PROFILE_DIR / "shadow_profile.json"

# Patterns for speech style detection
_HONORIFIC_PATTERNS = {
    "í•´ìš”ì²´": re.compile(r"(í•´ìš”|ì—ìš”|ì´ì—ìš”|ì„¸ìš”|ë„¤ìš”|ì£ )\b"),
    "í•©ì‡¼ì²´": re.compile(r"(í•©ë‹ˆë‹¤|ì…ë‹ˆë‹¤|ìŠµë‹ˆë‹¤|ë©ë‹ˆë‹¤)\b"),
    "í•´ì²´": re.compile(r"(í•´|ì•¼|ì§€|ê±°ë“ |ì–ì•„|ì¸ë°)\b"),
    "í•˜ì˜¤ì²´": re.compile(r"(í•˜ì˜¤|ì‹œì˜¤|êµ¬ë ¤|ì†Œ)\b"),
}

_EMOJI_RE = re.compile(
    r"[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF"
    r"\U0001F680-\U0001F6FF\U0001F900-\U0001F9FF"
    r"\U00002702-\U000027B0\U0000FE00-\U0000FE0F"
    r"\U0001FA00-\U0001FA6F\U0001FA70-\U0001FAFF"
    r"\U00002600-\U000026FF\U0000200D]+",
    re.UNICODE,
)

_SPLIT_SUGGEST_PATTERNS = re.compile(
    r"(ì–´ë–»ê²Œ\s*ìƒê°|ì¥ë‹¨ì |ë¹„êµí•´\s*ì¤˜|ì°¬ë°˜|pros\s*and\s*cons)", re.IGNORECASE
)

# Stop words to exclude from frequent-word analysis
_STOP_WORDS = frozenset(
    "ì€ëŠ”ì´ê°€ì„ë¥¼ì—ì„œì˜ë„ì™€ë¡œìœ¼ë¡œë§Œë„ê¹Œì§€ë¶€í„°"
    "ê·¸ ì´ ì € ê²ƒ ìˆ˜ ë” ì˜ ì¢€ ì•ˆ ëª» ë‹¤ ë˜".split()
)


class ShadowMode:
    """Learn user messaging style and generate proxy replies when absent."""

    def __init__(self) -> None:
        self.active: bool = False
        self.confidence_threshold: int = 70
        self.suffix: str = " [Shadow Mode]"
        self.profile: Dict[str, Any] = {}
        self._load_profile()

    # â”€â”€ Profile persistence â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _load_profile(self) -> None:
        try:
            if _PROFILE_PATH.exists():
                self.profile = json.loads(_PROFILE_PATH.read_text("utf-8"))
                self.confidence_threshold = self.profile.get(
                    "confidence_threshold", 70
                )
        except Exception as exc:
            log.warning("shadow: failed to load profile: %s", exc)

    def _save_profile(self) -> None:
        try:
            _PROFILE_DIR.mkdir(parents=True, exist_ok=True)
            self.profile["confidence_threshold"] = self.confidence_threshold
            _PROFILE_PATH.write_text(
                json.dumps(self.profile, ensure_ascii=False, indent=2), "utf-8"
            )
        except Exception as exc:
            log.warning("shadow: failed to save profile: %s", exc)

    # â”€â”€ Learning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def learn(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyse *user* messages and build a style profile."""
        user_msgs: List[str] = [
            m["content"]
            for m in messages
            if m.get("role") == "user" and isinstance(m.get("content"), str)
        ]
        if not user_msgs:
            return self.profile

        # Average message length
        lengths = [len(m) for m in user_msgs]
        avg_len = sum(lengths) / len(lengths)

        # Frequent words
        word_counter: Counter = Counter()
        for msg in user_msgs:
            tokens = re.findall(r"[ê°€-í£a-zA-Z0-9]+", msg)
            for t in tokens:
                if t.lower() not in _STOP_WORDS and len(t) > 1:
                    word_counter[t] += 1
        frequent_words = [w for w, _ in word_counter.most_common(30)]

        # Emoji usage
        emoji_counter: Counter = Counter()
        for msg in user_msgs:
            for match in _EMOJI_RE.finditer(msg):
                emoji_counter[match.group()] += 1
        emoji_top = [e for e, _ in emoji_counter.most_common(10)]

        # Response speed pattern (gap analysis via timestamps if available)
        timestamps = [
            m.get("timestamp", 0)
            for m in messages
            if m.get("role") == "user" and m.get("timestamp")
        ]
        speed_label = "unknown"
        if len(timestamps) >= 2:
            gaps = [
                timestamps[i + 1] - timestamps[i]
                for i in range(len(timestamps) - 1)
                if timestamps[i + 1] > timestamps[i]
            ]
            if gaps:
                avg_gap = sum(gaps) / len(gaps)
                speed_label = "ì¦‰ë‹µ" if avg_gap < 30 else "ìˆ™ê³ "

        # Speech style detection
        style_scores: Dict[str, int] = {}
        for style_name, pat in _HONORIFIC_PATTERNS.items():
            count = sum(len(pat.findall(m)) for m in user_msgs)
            if count:
                style_scores[style_name] = count
        dominant_style = (
            max(style_scores, key=style_scores.get) if style_scores else "í˜¼í•©"
        )

        # Sentence-start patterns
        start_counter: Counter = Counter()
        for msg in user_msgs:
            first_word = msg.strip().split()[0] if msg.strip() else ""
            if first_word:
                start_counter[first_word] += 1
        common_starts = [s for s, _ in start_counter.most_common(10)]

        self.profile = {
            "avg_message_length": round(avg_len, 1),
            "frequent_words": frequent_words,
            "emoji_top": emoji_top,
            "response_speed": speed_label,
            "speech_style": dominant_style,
            "speech_style_scores": style_scores,
            "common_starts": common_starts,
            "sample_count": len(user_msgs),
            "learned_at": time.time(),
            "confidence_threshold": self.confidence_threshold,
        }
        self._save_profile()
        return self.profile

    # â”€â”€ Proxy response generation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def build_proxy_prompt(self, incoming_message: str) -> str:
        """Build an LLM system prompt that mimics the user's style."""
        p = self.profile
        if not p:
            return ""
        lines = [
            "ë‹¤ìŒ ì‚¬ìš©ìì˜ ìŠ¤íƒ€ì¼ì„ ëª¨ë°©í•˜ì—¬ ì‘ë‹µí•˜ì‹œì˜¤.",
            f"- í‰ê·  ë©”ì‹œì§€ ê¸¸ì´: {p.get('avg_message_length', '?')}ì",
            f"- ë§íˆ¬: {p.get('speech_style', 'í˜¼í•©')}",
            f"- ìì£¼ ì“°ëŠ” ë‹¨ì–´: {', '.join(p.get('frequent_words', [])[:10])}",
            f"- ì´ëª¨ì§€: {' '.join(p.get('emoji_top', [])[:5])}",
            f"- ë¬¸ì¥ ì‹œì‘ íŒ¨í„´: {', '.join(p.get('common_starts', [])[:5])}",
            f"- ì‘ë‹µ ì†ë„ ê²½í–¥: {p.get('response_speed', 'unknown')}",
            "",
            f"ìˆ˜ì‹  ë©”ì‹œì§€: {incoming_message}",
        ]
        return "\n".join(lines)

    def generate_proxy_response(
        self, incoming_message: str, confidence: int = 80
    ) -> str:
        """Generate a proxy response. If confidence is below threshold, return a polite away message."""
        if confidence < self.confidence_threshold:
            return f"ì£¼ì¸ì´ ìë¦¬ë¥¼ ë¹„ì› ì†Œ.{self.suffix}"

        # In production this would call call_llm; here we build the prompt
        # and return a placeholder that the engine can feed to the LLM.
        prompt = self.build_proxy_prompt(incoming_message)
        if not prompt:
            return f"ì£¼ì¸ì´ ìë¦¬ë¥¼ ë¹„ì› ì†Œ.{self.suffix}"

        # Return a structured dict-like marker so the caller knows to LLM-call
        return prompt  # caller should pass this to LLM and append self.suffix

    def should_proxy(self) -> bool:
        """Return True if shadow mode is active and profile exists."""
        return self.active and bool(self.profile)

    # â”€â”€ Command handling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def handle_command(
        self, args: str, session_messages: Optional[List[Dict[str, Any]]] = None
    ) -> str:
        """Handle /shadow subcommands. Returns response text."""
        parts = args.strip().split(maxsplit=1)
        sub = parts[0].lower() if parts else ""
        rest = parts[1] if len(parts) > 1 else ""

        if sub == "on":
            self.active = True
            return "ğŸŒ‘ Shadow Mode í™œì„±í™” â€” ë¶€ì¬ ì¤‘ ëŒ€ë¦¬ ì‘ë‹µí•©ë‹ˆë‹¤."

        if sub == "off":
            self.active = False
            return "â˜€ï¸ Shadow Mode ë¹„í™œì„±í™” â€” ë³µê·€í–ˆìŠµë‹ˆë‹¤."

        if sub == "profile":
            if not self.profile:
                return "í”„ë¡œí•„ì´ ì—†ìŠµë‹ˆë‹¤. `/shadow learn`ìœ¼ë¡œ í•™ìŠµí•˜ì„¸ìš”."
            return json.dumps(self.profile, ensure_ascii=False, indent=2)

        if sub == "learn":
            msgs = session_messages or []
            profile = self.learn(msgs)
            return f"í•™ìŠµ ì™„ë£Œ â€” {profile.get('sample_count', 0)}ê°œ ë©”ì‹œì§€ ë¶„ì„ë¨."

        if sub == "test":
            if not rest:
                return "ì‚¬ìš©ë²•: `/shadow test <ë©”ì‹œì§€>`"
            prompt = self.build_proxy_prompt(rest)
            if not prompt:
                return "í”„ë¡œí•„ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € `/shadow learn`ì„ ì‹¤í–‰í•˜ì„¸ìš”."
            return f"[í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸]\n{prompt}{self.suffix}"

        if sub == "confidence":
            if not rest or not rest.isdigit():
                return f"í˜„ì¬ í™•ì‹ ë„ ì„ê³„ê°’: {self.confidence_threshold}\nì‚¬ìš©ë²•: `/shadow confidence <0-100>`"
            val = max(0, min(100, int(rest)))
            self.confidence_threshold = val
            if self.profile:
                self.profile["confidence_threshold"] = val
                self._save_profile()
            return f"í™•ì‹ ë„ ì„ê³„ê°’ì„ {val}(ìœ¼)ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤."

        return (
            "ì‚¬ìš©ë²•:\n"
            "  /shadow on â€” í™œì„±í™”\n"
            "  /shadow off â€” ë¹„í™œì„±í™”\n"
            "  /shadow profile â€” í”„ë¡œí•„ ì¡°íšŒ\n"
            "  /shadow learn â€” ì¬í•™ìŠµ\n"
            "  /shadow test <ë©”ì‹œì§€> â€” í…ŒìŠ¤íŠ¸\n"
            "  /shadow confidence <0-100> â€” ì„ê³„ê°’"
        )
