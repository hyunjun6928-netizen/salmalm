import subprocess
import sys
import os
import re
import time
import json
import traceback
import uuid
import urllib.request
import base64
import mimetypes
try:
    import resource as _resource_mod
except ImportError:
    _resource_mod = None  # Windows
import difflib
import threading
from datetime import datetime

from pathlib import Path
from typing import Dict

from .constants import (EXEC_ALLOWLIST, EXEC_BLOCKLIST, EXEC_BLOCKLIST_PATTERNS, PROTECTED_FILES,
                        WORKSPACE_DIR, VERSION, KST, MEMORY_FILE, MEMORY_DIR, AUDIT_DB)
from .crypto import vault, log
from .core import (audit_log, get_usage_report, _tfidf, SubAgent, SkillLoader,
                   _sessions, get_session, _tg_bot)
from .llm import _http_post, _http_get

# Global telegram bot reference (set during startup)
telegram_bot = None

# clipboard race condition ë°©ì§€ìš© lock
_clipboard_lock = threading.Lock()

TOOL_DEFINITIONS = [
    {
        'name': 'exec',
        'description': 'ì…¸ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ìœ„í—˜í•œ ëª…ë ¹ì€ ì°¨ë‹¨ë©ë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'command': {'type': 'string', 'description': 'ì‹¤í–‰í•  ì…¸ ëª…ë ¹ì–´'},
                'timeout': {'type': 'integer', 'description': 'íƒ€ì„ì•„ì›ƒ(ì´ˆ)', 'default': 30}
            },
            'required': ['command']
        }
    },
    {
        'name': 'read_file',
        'description': 'íŒŒì¼ ë‚´ìš©ì„ ì½ìŠµë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'path': {'type': 'string', 'description': 'íŒŒì¼ ê²½ë¡œ'},
                'offset': {'type': 'integer', 'description': 'ì‹œì‘ ì¤„ ë²ˆí˜¸ (1-based)'},
                'limit': {'type': 'integer', 'description': 'ì½ì„ ì¤„ ìˆ˜'}
            },
            'required': ['path']
        }
    },
    {
        'name': 'write_file',
        'description': 'íŒŒì¼ì— ë‚´ìš©ì„ ì”ë‹ˆë‹¤. ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'path': {'type': 'string', 'description': 'íŒŒì¼ ê²½ë¡œ'},
                'content': {'type': 'string', 'description': 'íŒŒì¼ ë‚´ìš©'}
            },
            'required': ['path', 'content']
        }
    },
    {
        'name': 'edit_file',
        'description': 'íŒŒì¼ì—ì„œ íŠ¹ì • í…ìŠ¤íŠ¸ë¥¼ ì°¾ì•„ êµì²´í•©ë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'path': {'type': 'string', 'description': 'íŒŒì¼ ê²½ë¡œ'},
                'old_text': {'type': 'string', 'description': 'ì°¾ì„ í…ìŠ¤íŠ¸'},
                'new_text': {'type': 'string', 'description': 'ë°”ê¿€ í…ìŠ¤íŠ¸'}
            },
            'required': ['path', 'old_text', 'new_text']
        }
    },
    {
        'name': 'web_search',
        'description': 'ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'query': {'type': 'string', 'description': 'ê²€ìƒ‰ ì¿¼ë¦¬'},
                'count': {'type': 'integer', 'description': 'ê²°ê³¼ ìˆ˜', 'default': 5}
            },
            'required': ['query']
        }
    },
    {
        'name': 'web_fetch',
        'description': 'URLì—ì„œ ë‚´ìš©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'url': {'type': 'string', 'description': 'URL'},
                'max_chars': {'type': 'integer', 'description': 'ìµœëŒ€ ê¸€ì ìˆ˜', 'default': 10000}
            },
            'required': ['url']
        }
    },
    {
        'name': 'memory_read',
        'description': 'MEMORY.md ë˜ëŠ” memory/ íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'file': {'type': 'string', 'description': 'íŒŒì¼ëª… (ì˜ˆ: MEMORY.md, 2026-02-18.md)'}
            },
            'required': ['file']
        }
    },
    {
        'name': 'memory_write',
        'description': 'MEMORY.md ë˜ëŠ” memory/ íŒŒì¼ì— ì”ë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'file': {'type': 'string', 'description': 'íŒŒì¼ëª…'},
                'content': {'type': 'string', 'description': 'ë‚´ìš©'}
            },
            'required': ['file', 'content']
        }
    },
    {
        'name': 'usage_report',
        'description': 'í˜„ì¬ ì„¸ì…˜ì˜ í† í° ì‚¬ìš©ëŸ‰ê³¼ ë¹„ìš©ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.',
        'input_schema': {'type': 'object', 'properties': {}}
    },
    {
        'name': 'memory_search',
        'description': 'MEMORY.mdì™€ memory/*.md íŒŒì¼ì—ì„œ í‚¤ì›Œë“œë¡œ ê´€ë ¨ ë‚´ìš©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'query': {'type': 'string', 'description': 'ê²€ìƒ‰í•  í‚¤ì›Œë“œ ë˜ëŠ” ë¬¸ì¥'},
                'max_results': {'type': 'integer', 'description': 'ìµœëŒ€ ê²°ê³¼ ìˆ˜', 'default': 5}
            },
            'required': ['query']
        }
    },
    {
        'name': 'image_generate',
        'description': 'ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. xAI Aurora ë˜ëŠ” OpenAI DALL-Eë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'prompt': {'type': 'string', 'description': 'ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ (ì˜ì–´ ê¶Œì¥)'},
                'provider': {'type': 'string', 'description': 'xai ë˜ëŠ” openai', 'default': 'xai'},
                'size': {'type': 'string', 'description': 'ì´ë¯¸ì§€ í¬ê¸°', 'default': '1024x1024'}
            },
            'required': ['prompt']
        }
    },
    {
        'name': 'tts',
        'description': 'í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤ (OpenAI TTS).',
        'input_schema': {
            'type': 'object',
            'properties': {
                'text': {'type': 'string', 'description': 'ë³€í™˜í•  í…ìŠ¤íŠ¸'},
                'voice': {'type': 'string', 'description': 'alloy, echo, fable, onyx, nova, shimmer', 'default': 'nova'}
            },
            'required': ['text']
        }
    },
    {
        'name': 'python_eval',
        'description': 'Python ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ìˆ˜í•™ ê³„ì‚°, ë°ì´í„° ì²˜ë¦¬, ë¶„ì„ì— ìœ ìš©í•©ë‹ˆë‹¤. exec()ë¡œ ì‹¤í–‰ í›„ _result ë³€ìˆ˜ì— ë‹´ê¸´ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'code': {'type': 'string', 'description': 'ì‹¤í–‰í•  Python ì½”ë“œ. ê²°ê³¼ë¥¼ _result ë³€ìˆ˜ì— í• ë‹¹í•˜ì„¸ìš”.'},
                'timeout': {'type': 'integer', 'description': 'íƒ€ì„ì•„ì›ƒ(ì´ˆ)', 'default': 15}
            },
            'required': ['code']
        }
    },
    {
        'name': 'system_monitor',
        'description': 'ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤ (CPU, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬, í”„ë¡œì„¸ìŠ¤).',
        'input_schema': {
            'type': 'object',
            'properties': {
                'detail': {'type': 'string', 'description': 'overview(ì „ì²´), cpu, memory, disk, processes, network ì¤‘ íƒ1', 'default': 'overview'}
            },
            'required': []
        }
    },
    {
        'name': 'http_request',
        'description': 'HTTP ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤ (GET/POST/PUT/DELETE). API í˜¸ì¶œì— ìœ ìš©í•©ë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'method': {'type': 'string', 'description': 'GET, POST, PUT, DELETE', 'default': 'GET'},
                'url': {'type': 'string', 'description': 'ìš”ì²­ URL'},
                'headers': {'type': 'object', 'description': 'ìš”ì²­ í—¤ë” (JSON)'},
                'body': {'type': 'string', 'description': 'ìš”ì²­ ë°”ë”” (POST/PUTìš©)'},
                'timeout': {'type': 'integer', 'description': 'íƒ€ì„ì•„ì›ƒ(ì´ˆ)', 'default': 15}
            },
            'required': ['url']
        }
    },
    {
        'name': 'screenshot',
        'description': 'í˜„ì¬ í™”ë©´ì„ ìŠ¤í¬ë¦°ìƒ·ìœ¼ë¡œ ìº¡ì²˜í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ê¸°ë¡ìš©ìœ¼ë¡œ ìœ ìš©í•©ë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'region': {'type': 'string', 'description': 'full(ì „ì²´í™”ë©´) ë˜ëŠ” WxH+X+Y (ì˜ì—­ ì§€ì •)', 'default': 'full'}
            },
            'required': []
        }
    },
    {
        'name': 'json_query',
        'description': 'JSON ë°ì´í„°ë¥¼ jq ìŠ¤íƒ€ì¼ë¡œ ì¿¼ë¦¬í•©ë‹ˆë‹¤. API ì‘ë‹µ íŒŒì‹±, ì„¤ì • íŒŒì¼ ë¶„ì„ì— ìœ ìš©í•©ë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'data': {'type': 'string', 'description': 'JSON ë¬¸ìì—´ ë˜ëŠ” íŒŒì¼ ê²½ë¡œ'},
                'query': {'type': 'string', 'description': 'jq í•„í„° í‘œí˜„ì‹ (ì˜ˆ: .items[].name)'},
                'from_file': {'type': 'boolean', 'description': 'dataê°€ íŒŒì¼ ê²½ë¡œì¸ ê²½ìš° true', 'default': False}
            },
            'required': ['data', 'query']
        }
    },
    {
        'name': 'diff_files',
        'description': 'ë‘ íŒŒì¼ ë˜ëŠ” ë‘ í…ìŠ¤íŠ¸ì˜ ì°¨ì´ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'file1': {'type': 'string', 'description': 'ì²« ë²ˆì§¸ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” í…ìŠ¤íŠ¸'},
                'file2': {'type': 'string', 'description': 'ë‘ ë²ˆì§¸ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” í…ìŠ¤íŠ¸'},
                'context_lines': {'type': 'integer', 'description': 'ì»¨í…ìŠ¤íŠ¸ ì¤„ ìˆ˜', 'default': 3}
            },
            'required': ['file1', 'file2']
        }
    },
    {
        'name': 'sub_agent',
        'description': 'ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì¥ì‹œê°„ ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ì¦‰ì‹œ ë°˜í™˜ë˜ê³  ì™„ë£Œ ì‹œ í…”ë ˆê·¸ë¨ìœ¼ë¡œ ì•Œë¦¼.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'action': {'type': 'string', 'description': 'spawn(ìƒì„±), list(ëª©ë¡), result(ê²°ê³¼)', 'enum': ['spawn', 'list', 'result']},
                'task': {'type': 'string', 'description': 'ì‹¤í–‰í•  ì‘ì—… ì„¤ëª… (spawnìš©)'},
                'model': {'type': 'string', 'description': 'ì‚¬ìš©í•  ëª¨ë¸ (optional)'},
                'agent_id': {'type': 'string', 'description': 'ì—ì´ì „íŠ¸ ID (resultìš©)'}
            },
            'required': ['action']
        }
    },
    {
        'name': 'skill_manage',
        'description': 'ìŠ¤í‚¬ì„ ì¡°íšŒí•˜ê³  ë¡œë“œí•©ë‹ˆë‹¤. skills/ í´ë”ì˜ SKILL.md ê¸°ë°˜ íŠ¹í™” ì§€ì¹¨.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'action': {'type': 'string', 'description': 'list(ëª©ë¡), load(ë¡œë“œ), match(ìë™ë§¤ì¹­)', 'enum': ['list', 'load', 'match']},
                'skill_name': {'type': 'string', 'description': 'ìŠ¤í‚¬ ë””ë ‰í† ë¦¬ëª… (loadìš©)'},
                'query': {'type': 'string', 'description': 'ë§¤ì¹­í•  ì¿¼ë¦¬ (matchìš©)'}
            },
            'required': ['action']
        }
    },
    {
        'name': 'clipboard',
        'description': 'í…ìŠ¤íŠ¸ í´ë¦½ë³´ë“œ. ì„¸ì…˜ ê°„ ë¹ ë¥¸ ë³µì‚¬/ë¶™ì—¬ë„£ê¸°/ëª©ë¡ ì¡°íšŒ. ìµœëŒ€ 50ê°œ ìŠ¬ë¡¯.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'action': {'type': 'string', 'description': 'copy(ì €ì¥), paste(ì½ê¸°), list(ëª©ë¡), clear(ì „ì²´ì‚­ì œ)', 'enum': ['copy', 'paste', 'list', 'clear']},
                'slot': {'type': 'string', 'description': 'ìŠ¬ë¡¯ ì´ë¦„ (ê¸°ë³¸: default)'},
                'content': {'type': 'string', 'description': 'ì €ì¥í•  í…ìŠ¤íŠ¸ (copyìš©)'}
            },
            'required': ['action']
        }
    },
    {
        'name': 'hash_text',
        'description': 'í…ìŠ¤íŠ¸ í•´ì‹±(SHA256/MD5/SHA1) ë˜ëŠ” ëœë¤ ë¹„ë°€ë²ˆí˜¸/UUID/í† í° ìƒì„±.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'action': {'type': 'string', 'description': 'hash(í•´ì‹±), password(ë¹„ë°€ë²ˆí˜¸ìƒì„±), uuid(UUIDìƒì„±), token(ëœë¤í† í°)', 'enum': ['hash', 'password', 'uuid', 'token']},
                'text': {'type': 'string', 'description': 'í•´ì‹±í•  í…ìŠ¤íŠ¸ (hashìš©)'},
                'algorithm': {'type': 'string', 'description': 'sha256, md5, sha1, sha512, sha384 (ê¸°ë³¸: sha256)'},
                'length': {'type': 'integer', 'description': 'ë¹„ë°€ë²ˆí˜¸/í† í° ê¸¸ì´ (ê¸°ë³¸: 16)'}
            },
            'required': ['action']
        }
    },
    {
        'name': 'regex_test',
        'description': 'ì •ê·œí‘œí˜„ì‹ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. íŒ¨í„´ ë§¤ì¹­, ì¹˜í™˜, ì¶”ì¶œì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'pattern': {'type': 'string', 'description': 'ì •ê·œí‘œí˜„ì‹ íŒ¨í„´'},
                'text': {'type': 'string', 'description': 'ëŒ€ìƒ í…ìŠ¤íŠ¸'},
                'action': {'type': 'string', 'description': 'match(ì „ì²´ë§¤ì¹­), find(ëª¨ë‘ì°¾ê¸°), replace(ì¹˜í™˜), split(ë¶„í• )', 'enum': ['match', 'find', 'replace', 'split']},
                'replacement': {'type': 'string', 'description': 'ì¹˜í™˜í•  í…ìŠ¤íŠ¸ (replaceìš©)'},
                'flags': {'type': 'string', 'description': 'í”Œë˜ê·¸: i(ëŒ€ì†Œë¬¸ìë¬´ì‹œ), m(ë©€í‹°ë¼ì¸), s(dotall)'}
            },
            'required': ['pattern', 'text']
        }
    },
    {
        'name': 'cron_manage',
        'description': 'ìŠ¤ì¼€ì¤„ ì‘ì—… ê´€ë¦¬. ë§¤ì¼/ë§¤ì‹œê°„/íŠ¹ì • ì‹œê°„ì— LLM ì‘ì—…ì„ ìë™ ì‹¤í–‰í•©ë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'action': {'type': 'string', 'description': 'list(ëª©ë¡), add(ì¶”ê°€), remove(ì‚­ì œ), toggle(í™œì„±/ë¹„í™œì„±)', 'enum': ['list', 'add', 'remove', 'toggle']},
                'name': {'type': 'string', 'description': 'ì‘ì—… ì´ë¦„ (addìš©)'},
                'prompt': {'type': 'string', 'description': 'LLMì— ë³´ë‚¼ í”„ë¡¬í”„íŠ¸ (addìš©)'},
                'schedule': {'type': 'object', 'description': 'ìŠ¤ì¼€ì¤„: {"kind":"cron","expr":"0 6 * * *"} ë˜ëŠ” {"kind":"every","seconds":3600} ë˜ëŠ” {"kind":"at","time":"ISO8601"}'},
                'model': {'type': 'string', 'description': 'ì‚¬ìš©í•  ëª¨ë¸ (ì„ íƒ, ê¸°ë³¸: í˜„ì¬ ì„¤ì •)'},
                'job_id': {'type': 'string', 'description': 'ì‘ì—… ID (remove/toggleìš©)'}
            },
            'required': ['action']
        }
    },
    {
        'name': 'plugin_manage',
        'description': 'í”ŒëŸ¬ê·¸ì¸ ê´€ë¦¬. plugins/ í´ë”ì˜ .py íŒŒì¼ì„ ìë™ ë¡œë“œí•˜ì—¬ ë„êµ¬ë¥¼ í™•ì¥í•©ë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'action': {'type': 'string', 'description': 'list(ëª©ë¡), reload(ì¬ë¡œë“œ)', 'enum': ['list', 'reload']}
            },
            'required': ['action']
        }
    },
    {
        'name': 'mcp_manage',
        'description': 'MCP (Model Context Protocol) ì„œë²„ ê´€ë¦¬. ì™¸ë¶€ MCP ì„œë²„ì— ì—°ê²°í•˜ì—¬ ë„êµ¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'action': {'type': 'string', 'description': 'list(ëª©ë¡), add(ì¶”ê°€), remove(ì‚­ì œ), tools(ì „ì²´ ë„êµ¬ ëª©ë¡)', 'enum': ['list', 'add', 'remove', 'tools']},
                'name': {'type': 'string', 'description': 'ì„œë²„ ì´ë¦„ (add/removeìš©)'},
                'command': {'type': 'string', 'description': 'ì„œë²„ ì‹¤í–‰ ëª…ë ¹ì–´ (addìš©, ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬)'},
                'env': {'type': 'object', 'description': 'í™˜ê²½ ë³€ìˆ˜ (addìš©, ì„ íƒ)'},
            },
            'required': ['action']
        }
    },
    {
        'name': 'rag_search',
        'description': 'ë¡œì»¬ RAG (BM25) ê²€ìƒ‰. MEMORY.md, memory/, uploads/ ë“±ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ìŠµë‹ˆë‹¤.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'query': {'type': 'string', 'description': 'ê²€ìƒ‰ ì¿¼ë¦¬'},
                'max_results': {'type': 'integer', 'description': 'ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ 5)', 'default': 5},
            },
            'required': ['query']
        }
    },
    {
        'name': 'browser',
        'description': 'ë¸Œë¼ìš°ì € ìë™í™”. Chrome CDPë¡œ í˜ì´ì§€ íƒìƒ‰, ìŠ¤í¬ë¦°ìƒ·, JS ì‹¤í–‰, í…ìŠ¤íŠ¸ ì¶”ì¶œ ë“±.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'action': {'type': 'string', 'description': 'navigate/screenshot/text/html/evaluate/click/type/tabs/pdf/status', 'enum': ['navigate', 'screenshot', 'text', 'html', 'evaluate', 'click', 'type', 'tabs', 'pdf', 'status', 'connect', 'console']},
                'url': {'type': 'string', 'description': 'URL (navigateìš©)'},
                'selector': {'type': 'string', 'description': 'CSS selector (click/typeìš©)'},
                'expression': {'type': 'string', 'description': 'JavaScript ì½”ë“œ (evaluateìš©)'},
                'text': {'type': 'string', 'description': 'ì…ë ¥ í…ìŠ¤íŠ¸ (typeìš©)'},
            },
            'required': ['action']
        }
    },
    {
        'name': 'node_manage',
        'description': 'ì›ê²© ë…¸ë“œ ê´€ë¦¬. SSH/HTTPë¡œ ì›ê²© ì„œë²„ ëª…ë ¹ ì‹¤í–‰, ìƒíƒœ í™•ì¸, íŒŒì¼ ì „ì†¡.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'action': {'type': 'string', 'description': 'list/add/remove/run/status/upload/wake', 'enum': ['list', 'add', 'remove', 'run', 'status', 'upload', 'wake']},
                'name': {'type': 'string', 'description': 'ë…¸ë“œ ì´ë¦„'},
                'command': {'type': 'string', 'description': 'ì‹¤í–‰í•  ëª…ë ¹ì–´ (runìš©)'},
                'host': {'type': 'string', 'description': 'í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ (addìš©)'},
                'user': {'type': 'string', 'description': 'SSH ì‚¬ìš©ì (ê¸°ë³¸: root)'},
                'port': {'type': 'integer', 'description': 'SSH í¬íŠ¸ (ê¸°ë³¸: 22)'},
                'key': {'type': 'string', 'description': 'SSH í‚¤ ê²½ë¡œ'},
                'type': {'type': 'string', 'description': 'ë…¸ë“œ íƒ€ì…: ssh/http'},
                'url': {'type': 'string', 'description': 'HTTP ì—ì´ì „íŠ¸ URL (add type=httpìš©)'},
                'mac': {'type': 'string', 'description': 'MAC ì£¼ì†Œ (wakeìš©)'},
            },
            'required': ['action']
        }
    },
    {
        'name': 'health_check',
        'description': 'ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ í™•ì¸. ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ìƒíƒœ, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬, ì—ëŸ¬ìœ¨ ë“± ì¢…í•© ì§„ë‹¨.',
        'input_schema': {
            'type': 'object',
            'properties': {
                'action': {'type': 'string', 'description': 'check(ì¢…í•©ì§„ë‹¨)/selftest(ëª¨ë“ˆí…ŒìŠ¤íŠ¸)/recover(ìë™ë³µêµ¬)', 'enum': ['check', 'selftest', 'recover'], 'default': 'check'},
            },
        }
    },
]


def _is_safe_command(cmd: str) -> tuple[bool, str]:
    """Check if command is safe to execute (allowlist + blocklist double defense)."""
    first_word = cmd.strip().split()[0].split('/')[-1] if cmd.strip() else ''
    if not first_word:
        return False, 'Empty command'
    # Blocklist takes priority (even if somehow in allowlist)
    if first_word in EXEC_BLOCKLIST:
        return False, f'Blocked command: {first_word}'
    for pattern in EXEC_BLOCKLIST_PATTERNS:
        if re.search(pattern, cmd):
            return False, f'Blocked pattern: {pattern}'
    # Allowlist check â€” unknown commands blocked
    if first_word not in EXEC_ALLOWLIST:
        return False, f'Command not in allowlist: {first_word} (not in EXEC_ALLOWLIST)'
    return True, ''


def _resolve_path(path: str, writing: bool = False) -> Path:
    """Resolve path, preventing traversal outside allowed directories.

    Read: workspace + home directory
    Write: workspace only (stricter)
    """
    p = Path(path)
    if not p.is_absolute():
        p = WORKSPACE_DIR / p
    p = p.resolve()

    if writing:
        # Write operations: workspace only
        try:
            p.relative_to(WORKSPACE_DIR.resolve())
        except ValueError:
            raise PermissionError(f'ì“°ê¸° ë¶ˆê°€ (workspace ì™¸ë¶€): {p}')
    else:
        # Read operations: workspace + home
        allowed = [WORKSPACE_DIR.resolve(), Path.home().resolve()]
        if not any(_is_subpath(p, a) for a in allowed):
            raise PermissionError(f'ì ‘ê·¼ ë¶ˆê°€: {p}')

    if writing and p.name in PROTECTED_FILES:
        raise PermissionError(f'ë³´í˜¸ëœ íŒŒì¼: {p.name}')
    return p


def _is_subpath(path: Path, parent: Path) -> bool:
    """Check if path is under parent (safe, no startswith tricks)."""
    try:
        path.relative_to(parent)
        return True
    except ValueError:
        return False


def execute_tool(name: str, args: dict) -> str:
    """Execute a tool and return result string."""
    audit_log('tool_exec', f'{name}: {json.dumps(args, ensure_ascii=False)[:200]}')
    try:
        if name == 'exec':
            cmd = args.get('command', '')
            safe, reason = _is_safe_command(cmd)
            if not safe:
                return f'âŒ {reason}'
            timeout = min(args.get('timeout', 30), 120)
            try:
                # Use shell=False by default (safer), shell=True only for pipes/redirects
                import shlex
                needs_shell = any(c in cmd for c in ['|', '>', '<', '&&', '||', ';', '`', '$(' ])
                if needs_shell:
                    run_args = {'args': cmd, 'shell': True}
                else:
                    try:
                        run_args = {'args': shlex.split(cmd), 'shell': False}
                    except ValueError:
                        run_args = {'args': cmd, 'shell': True}
                result = subprocess.run(
                    **run_args, capture_output=True, text=True,
                    timeout=timeout, cwd=str(WORKSPACE_DIR)
                )
                output = result.stdout[-5000:] if result.stdout else ''
                if result.stderr:
                    output += f'\n[stderr]: {result.stderr[-2000:]}'
                if result.returncode != 0:
                    output += f'\n[exit code]: {result.returncode}'
                return output or '(no output)'
            except subprocess.TimeoutExpired:
                return f'âŒ Timeout ({timeout}s)'

        elif name == 'read_file':
            p = _resolve_path(args['path'])
            if not p.exists():
                return f'âŒ File not found: {p}'
            text = p.read_text(encoding='utf-8', errors='replace')
            lines = text.splitlines()
            offset = args.get('offset', 1) - 1
            limit = args.get('limit', len(lines))
            selected = lines[offset:offset + limit]
            return '\n'.join(selected)[:50000]

        elif name == 'write_file':
            p = _resolve_path(args['path'], writing=True)
            p.parent.mkdir(parents=True, exist_ok=True)
            p.write_text(args['content'], encoding='utf-8')
            return f'âœ… {p} ({len(args["content"])} chars)'

        elif name == 'edit_file':
            p = _resolve_path(args['path'], writing=True)
            text = p.read_text(encoding='utf-8')
            if args['old_text'] not in text:
                return f'âŒ Text not found'
            text = text.replace(args['old_text'], args['new_text'], 1)
            p.write_text(text, encoding='utf-8')
            return f'âœ… File edited: {p}'

        elif name == 'web_search':
            api_key = vault.get('brave_api_key')
            if not api_key:
                return 'âŒ Brave Search API key not found'
            query = urllib.parse.quote(args['query'])
            count = min(args.get('count', 5), 10)
            resp = _http_get(
                f'https://api.search.brave.com/res/v1/web/search?q={query}&count={count}',
                {'Accept': 'application/json', 'X-Subscription-Token': api_key}
            )
            results = []
            for r in resp.get('web', {}).get('results', [])[:count]:
                results.append(f"**{r['title']}**\n{r['url']}\n{r.get('description', '')}\n")
            return '\n'.join(results) or 'No results'

        elif name == 'web_fetch':
            url = args['url']
            max_chars = args.get('max_chars', 10000)
            # SSRF protection: block internal/private IPs
            from urllib.parse import urlparse
            _host = urlparse(url).hostname or ''
            _blocked = ('localhost', '127.', '10.', '192.168.', '172.16.',
                        '172.17.', '172.18.', '172.19.', '172.2', '172.30.', '172.31.',
                        '169.254.', '0.0.0.0', '::1', 'metadata.google', '169.254.169.254')
            if any(_host.startswith(b) or _host == b for b in _blocked):
                return f'âŒ Internal network access blocked: {_host}'
            req = urllib.request.Request(url, headers={
                'User-Agent': 'Mozilla/5.0 (SalmAlm/0.1)'
            })
            with urllib.request.urlopen(req, timeout=15) as resp:
                raw = resp.read().decode('utf-8', errors='replace')
            # HTML to text using html.parser (robust, no regex fragility)
            from html.parser import HTMLParser

            class _TextExtractor(HTMLParser):
                def __init__(self):
                    super().__init__()
                    self._parts: list = []
                    self._skip = False
                    self._skip_tags = {'script', 'style', 'noscript', 'svg'}

                def handle_starttag(self, tag, attrs):
                    if tag.lower() in self._skip_tags:
                        self._skip = True
                    elif tag.lower() in ('br', 'p', 'div', 'li', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'tr'):
                        self._parts.append('\n')

                def handle_endtag(self, tag):
                    if tag.lower() in self._skip_tags:
                        self._skip = False

                def handle_data(self, data):
                    if not self._skip:
                        self._parts.append(data)

                def get_text(self) -> str:
                    return re.sub(r'\n{3,}', '\n\n', ''.join(self._parts)).strip()

            extractor = _TextExtractor()
            extractor.feed(raw)
            return extractor.get_text()[:max_chars]

        elif name == 'memory_read':
            fname = args['file']
            if fname == 'MEMORY.md':
                p = MEMORY_FILE
            else:
                p = MEMORY_DIR / fname
            if not p.exists():
                return f'âŒ File not found: {fname}'
            return p.read_text(encoding='utf-8')[:30000]

        elif name == 'memory_write':
            fname = args['file']
            if fname == 'MEMORY.md':
                p = MEMORY_FILE
            else:
                p = MEMORY_DIR / fname
            p.parent.mkdir(parents=True, exist_ok=True)
            p.write_text(args['content'], encoding='utf-8')
            return f'âœ… {fname} saved'

        elif name == 'usage_report':
            report = get_usage_report()
            lines = [f"ğŸ“Š ì‚¶ì• ì‚¬ìš©ëŸ‰ ë¦¬í¬íŠ¸",
                     f"â±ï¸ ê°€ë™: {report['elapsed_hours']}ì‹œê°„",
                     f"ğŸ“¥ ì…ë ¥: {report['total_input']:,} í† í°",
                     f"ğŸ“¤ ì¶œë ¥: {report['total_output']:,} í† í°",
                     f"ğŸ’° ì´ ë¹„ìš©: ${report['total_cost']:.4f}", ""]
            for m, d in report.get('by_model', {}).items():
                lines.append(f"  {m}: {d['calls']}íšŒ, ${d['cost']:.4f}")
            return '\n'.join(lines)

        elif name == 'memory_search':
            query = args['query']
            max_results = args.get('max_results', 5)
            # Use TF-IDF semantic search
            results = _tfidf.search(query, max_results)
            if not results:
                return f'No results for: "{query}"'
            out = []
            for score, label, lineno, snippet in results:
                out.append(f'ğŸ“ {label}#{lineno} (similarity:{score:.3f})\n{snippet}\n')
            return '\n'.join(out)

        elif name == 'sub_agent':
            action = args.get('action', 'list')
            if action == 'spawn':
                task = args.get('task', '')
                if not task:
                    return 'âŒ Task is required'
                model = args.get('model')
                agent_id = SubAgent.spawn(task, model=model)
                return f'ğŸ¤– Sub-agent spawned: [{agent_id}]\nTask: {task[:100]}\nWill notify on completion.'
            elif action == 'list':
                agents = SubAgent.list_agents()
                if not agents:
                    return 'ğŸ“‹ No running sub-agents.'
                lines = []
                for a in agents:
                    icon = 'ğŸŸ¢' if a['status'] == 'running' else 'âœ…' if a['status'] == 'completed' else 'âŒ'
                    lines.append(f'{icon} [{a["id"]}] {a["task"]} â€” {a["status"]}')
                return '\n'.join(lines)
            elif action == 'result':
                agent_id = args.get('agent_id', '')
                info = SubAgent.get_result(agent_id)
                if 'error' in info:
                    return f'âŒ {info["error"]}'
                status = info['status']
                if status == 'running':
                    return f'â³ [{agent_id}] Still running.\nStarted: {info["started"]}'
                result = info.get('result', '(ê²°ê³¼ ì—†ìŒ)')
                return f'{"âœ…" if status == "completed" else "âŒ"} [{agent_id}] {status}\nStarted: {info["started"]}\nFinished: {info["completed"]}\n\n{result[:3000]}'
            return f'âŒ Unknown action: {action}'

        elif name == 'skill_manage':
            action = args.get('action', 'list')
            if action == 'list':
                skills = SkillLoader.scan()
                if not skills:
                    return 'ğŸ“š No skills registered.\nCreate a skill directory in skills/ and add SKILL.md.'
                lines = []
                for s in skills:
                    lines.append(f'ğŸ“š **{s["name"]}** ({s["dir_name"]})\n   {s["description"]}\n   í¬ê¸°: {s["size"]}ì')
                return '\n'.join(lines)
            elif action == 'load':
                skill_name = args.get('skill_name', '')
                content = SkillLoader.load(skill_name)
                if not content:
                    return f'âŒ Skill "{skill_name}" not found'
                return f'ğŸ“š Skill loaded: {skill_name}\n\n{content[:5000]}'
            elif action == 'match':
                query = args.get('query', '')
                content = SkillLoader.match(query)
                if not content:
                    return 'No matching skill found.'
                return f'ğŸ“š Auto-matched skill:\n\n{content[:5000]}'
            return f'âŒ Unknown action: {action}'

        elif name == 'image_generate':
            prompt = args['prompt']
            provider = args.get('provider', 'xai')
            size = args.get('size', '1024x1024')
            save_dir = WORKSPACE_DIR / 'uploads'
            save_dir.mkdir(exist_ok=True)
            fname = f"gen_{int(time.time())}.png"
            save_path = save_dir / fname

            if provider == 'xai':
                api_key = vault.get('xai_api_key')
                if not api_key:
                    return 'âŒ xAI API key not found'
                resp = _http_post(
                    'https://api.x.ai/v1/images/generations',
                    {'Authorization': f'Bearer {api_key}', 'Content-Type': 'application/json'},
                    {'model': 'aurora', 'prompt': prompt, 'n': 1, 'size': size,
                     'response_format': 'b64_json'}
                )
                import base64 as b64mod
                img_data = b64mod.b64decode(resp['data'][0]['b64_json'])
                save_path.write_bytes(img_data)
            else:
                api_key = vault.get('openai_api_key')
                if not api_key:
                    return 'âŒ OpenAI API key not found'
                resp = _http_post(
                    'https://api.openai.com/v1/images/generations',
                    {'Authorization': f'Bearer {api_key}', 'Content-Type': 'application/json'},
                    {'model': 'gpt-image-1', 'prompt': prompt, 'n': 1, 'size': size,
                     'output_format': 'b64_json'}
                )
                import base64 as b64mod
                img_data = b64mod.b64decode(resp['data'][0]['b64_json'])
                save_path.write_bytes(img_data)

            size_kb = len(img_data) / 1024
            log.info(f"ğŸ¨ Image generated: {fname} ({size_kb:.1f}KB)")
            return f'âœ… ì´ë¯¸ì§€ ìƒì„± Finished: uploads/{fname} ({size_kb:.1f}KB)\nPrompt: {prompt}'

        elif name == 'tts':
            text = args['text']
            voice = args.get('voice', 'nova')
            api_key = vault.get('openai_api_key')
            if not api_key:
                return 'âŒ OpenAI API key not found'
            save_dir = WORKSPACE_DIR / 'uploads'
            save_dir.mkdir(exist_ok=True)
            fname = f"tts_{int(time.time())}.mp3"
            save_path = save_dir / fname
            data = json.dumps({'model': 'tts-1', 'input': text, 'voice': voice}).encode()
            req = urllib.request.Request(
                'https://api.openai.com/v1/audio/speech',
                data=data,
                headers={'Authorization': f'Bearer {api_key}',
                         'Content-Type': 'application/json'},
                method='POST'
            )
            with urllib.request.urlopen(req, timeout=30) as resp:
                audio = resp.read()
            save_path.write_bytes(audio)
            size_kb = len(audio) / 1024
            log.info(f"ğŸ”Š TTS generated: {fname} ({size_kb:.1f}KB)")
            return f'âœ… ìŒì„± ìƒì„± Finished: uploads/{fname} ({size_kb:.1f}KB)\nText: {text[:100]}'

        elif name == 'python_eval':
            code = args.get('code', '')
            timeout_sec = min(args.get('timeout', 15), 30)
            # Block dangerous patterns in code
            _EVAL_BLOCKLIST = [
                'import os', 'import sys', 'import subprocess', 'import shutil',
                '__import__', 'eval(', 'exec(', 'compile(', 'open(',
                'os.system', 'os.popen', 'os.exec', 'os.spawn', 'os.remove', 'os.unlink',
                'shutil.rmtree', 'pathlib', '.vault', 'audit.db', 'auth.db',
                'import socket', 'import http', 'import urllib', 'import requests',
            ]
            code_lower = code.lower().replace(' ', '')
            for blocked in _EVAL_BLOCKLIST:
                if blocked.lower().replace(' ', '') in code_lower:
                    return f'âŒ Security blocked: `{blocked}` not allowed. python_eval is for computation only.'
            # Execute in isolated subprocess (no network, limited imports)
            wrapper = f'''
import json, math, re, statistics, collections, itertools, functools, datetime, hashlib, base64, random, string, textwrap, csv, io
_result = None
try:
    exec({repr(code)})
except Exception as e:
    _result = f"Error: {{type(e).__name__}}: {{e}}"
if _result is not None:
    print(json.dumps({{"result": str(_result)[:10000]}}))
else:
    print(json.dumps({{"result": "(no _result set)"}}))
'''
            # Resource limits (Linux only â€” graceful no-op on Windows/macOS)
            def _set_limits():
                try:
                    import resource
                    resource.setrlimit(resource.RLIMIT_CPU, (timeout_sec, timeout_sec))
                    resource.setrlimit(resource.RLIMIT_AS, (512 * 1024 * 1024, 512 * 1024 * 1024))  # 512MB
                    resource.setrlimit(resource.RLIMIT_NOFILE, (50, 50))  # fd limit
                    resource.setrlimit(resource.RLIMIT_NPROC, (10, 10))  # fork bomb prevention
                    resource.setrlimit(resource.RLIMIT_FSIZE, (10 * 1024 * 1024, 10 * 1024 * 1024))  # 10MB file write limit
                except Exception:
                    pass  # Windows or unsupported

            try:
                result = subprocess.run(
                    [sys.executable, '-c', wrapper],
                    capture_output=True, text=True,
                    timeout=timeout_sec, cwd=str(WORKSPACE_DIR),
                    preexec_fn=_set_limits
                )
                if result.returncode == 0 and result.stdout.strip():
                    try:
                        data = json.loads(result.stdout.strip())
                        output = data.get('result', result.stdout)
                    except json.JSONDecodeError:
                        output = result.stdout[-5000:]
                else:
                    output = result.stdout[-3000:] if result.stdout else ''
                if result.stderr:
                    output += f'\n[stderr]: {result.stderr[-2000:]}'
                return output or '(no output)'
            except subprocess.TimeoutExpired:
                return f'âŒ Python execution timeout ({timeout_sec}s)'

        elif name == 'system_monitor':
            detail = args.get('detail', 'overview')
            lines = []
            try:
                if detail in ('overview', 'cpu'):
                    load = os.getloadavg()
                    cpu_count = os.cpu_count() or 1
                    lines.append(f'ğŸ–¥ï¸ CPU: {cpu_count}ì½”ì–´, ë¶€í•˜: {load[0]:.2f} / {load[1]:.2f} / {load[2]:.2f} (1/5/15ë¶„)')
                if detail in ('overview', 'memory'):
                    mem = subprocess.run(['free', '-h'], capture_output=True, text=True, timeout=5)
                    if mem.stdout:
                        for l in mem.stdout.strip().split('\n'):
                            lines.append(f'ğŸ’¾ {l}')
                if detail in ('overview', 'disk'):
                    disk = subprocess.run(['df', '-h', '/'], capture_output=True, text=True, timeout=5)
                    if disk.stdout:
                        for l in disk.stdout.strip().split('\n'):
                            lines.append(f'ğŸ’¿ {l}')
                if detail in ('overview', 'network'):
                    # Quick network check
                    net = subprocess.run(['ss', '-s'], capture_output=True, text=True, timeout=5)
                    if net.stdout:
                        lines.append(f'ğŸŒ ë„¤íŠ¸ì›Œí¬:')
                        for l in net.stdout.strip().split('\n')[:5]:
                            lines.append(f'   {l}')
                if detail == 'processes':
                    ps = subprocess.run(['ps', 'aux', '--sort=-rss'], capture_output=True, text=True, timeout=5)
                    if ps.stdout:
                        for l in ps.stdout.strip().split('\n')[:20]:
                            lines.append(l)
                if detail in ('overview',):
                    uptime = subprocess.run(['uptime', '-p'], capture_output=True, text=True, timeout=5)
                    if uptime.stdout:
                        lines.append(f'â±ï¸ ê°€ë™ì‹œê°„: {uptime.stdout.strip()}')
                    # Python process info
                    mem_mb = 0
                    if _resource_mod:
                        mem_mb = _resource_mod.getrusage(_resource_mod.RUSAGE_SELF).ru_maxrss / 1024
                    lines.append(f'ğŸ ì‚¶ì• ë©”ëª¨ë¦¬: {mem_mb:.1f}MB')
                    lines.append(f'ğŸ“‚ ì„¸ì…˜ ìˆ˜: {len(_sessions)}')
            except Exception as e:
                lines.append(f'âŒ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}')
            return '\n'.join(lines) or 'ì •ë³´ ì—†ìŒ'

        elif name == 'http_request':
            method = args.get('method', 'GET').upper()
            url = args.get('url', '')
            headers = args.get('headers', {})
            body_str = args.get('body', '')
            timeout_sec = min(args.get('timeout', 15), 60)
            if not url:
                return 'âŒ URLì´ í•„ìš”í•©ë‹ˆë‹¤'
            # SSRF protection: block internal/private IPs
            from urllib.parse import urlparse
            _host = urlparse(url).hostname or ''
            _blocked = ('localhost', '127.', '10.', '192.168.', '172.16.',
                        '172.17.', '172.18.', '172.19.', '172.2', '172.30.', '172.31.',
                        '169.254.', '0.0.0.0', '::1', 'metadata.google', '169.254.169.254')
            if any(_host.startswith(b) or _host == b for b in _blocked):
                return f'âŒ Internal network access blocked: {_host}'
            headers.setdefault('User-Agent', f'SalmAlm/{VERSION}')
            data = body_str.encode('utf-8') if body_str else None
            try:
                req = urllib.request.Request(url, data=data, headers=headers, method=method)
                with urllib.request.urlopen(req, timeout=timeout_sec) as resp:
                    status = resp.status
                    resp_headers = dict(resp.headers)
                    raw = resp.read()
                # Try JSON
                try:
                    body_json = json.loads(raw)
                    body_out = json.dumps(body_json, ensure_ascii=False, indent=2)[:8000]
                except (json.JSONDecodeError, UnicodeDecodeError):
                    body_out = raw.decode('utf-8', errors='replace')[:8000]
                header_str = '\n'.join(f'  {k}: {v}' for k, v in list(resp_headers.items())[:10])
                return f'HTTP {status}\ní—¤ë”:\n{header_str}\n\në°”ë””:\n{body_out}'
            except urllib.error.HTTPError as e:
                body = e.read().decode('utf-8', errors='replace')[:3000]
                return f'HTTP {e.code} {e.reason}\n{body}'
            except Exception as e:
                return f'âŒ ìš”ì²­ ì˜¤ë¥˜: {e}'

        elif name == 'screenshot':
            region = args.get('region', 'full')
            fname = f'screenshot_{int(time.time())}.png'
            fpath = WORKSPACE_DIR / 'uploads' / fname
            fpath.parent.mkdir(exist_ok=True)
            try:
                cmd = ['import', '-window', 'root', str(fpath)] if region == 'full' else ['import', '-crop', region, '-window', 'root', str(fpath)]
                # Try scrot first (more common)
                try:
                    if region == 'full':
                        subprocess.run(['scrot', str(fpath)], timeout=10, check=True)
                    else:
                        subprocess.run(['scrot', '-a', region, str(fpath)], timeout=10, check=True)
                except FileNotFoundError:
                    subprocess.run(cmd, timeout=10, check=True)
                size_kb = fpath.stat().st_size / 1024
                return f'âœ… ìŠ¤í¬ë¦°ìƒ· ì €ì¥: uploads/{fname} ({size_kb:.1f}KB)'
            except Exception as e:
                return f'âŒ ìŠ¤í¬ë¦°ìƒ· ì‹¤íŒ¨: {e}'

        elif name == 'json_query':
            data_str = args.get('data', '')
            query = args.get('query', '.')
            from_file = args.get('from_file', False)
            if from_file:
                fpath = _resolve_path(data_str)
                data_str = fpath.read_text(encoding='utf-8', errors='replace')
            try:
                result = subprocess.run(
                    ['jq', query],
                    input=data_str, capture_output=True, text=True, timeout=10
                )
                if result.returncode == 0:
                    return result.stdout[:8000] or '(empty)'
                return f'âŒ jq ì˜¤ë¥˜: {result.stderr[:500]}'
            except FileNotFoundError:
                # jq not installed, try Python fallback
                data = json.loads(data_str)
                # Simple dot notation query
                parts = query.strip('.').split('.')
                current = data
                for p in parts:
                    if not p:
                        continue
                    if p.endswith('[]'):
                        p = p[:-2]
                        if p:
                            current = current[p]
                        if isinstance(current, list):
                            current = current
                    elif p.isdigit():
                        current = current[int(p)]
                    else:
                        current = current[p]
                return json.dumps(current, ensure_ascii=False, indent=2)[:8000]

        elif name == 'diff_files':
            f1 = args.get('file1', '')
            f2 = args.get('file2', '')
            ctx = args.get('context_lines', 3)
            import difflib
            # If paths exist, read them
            try:
                p1 = _resolve_path(f1)
                text1 = p1.read_text(encoding='utf-8', errors='replace').splitlines()
                label1 = f1
            except Exception:
                text1 = f1.splitlines()
                label1 = 'text1'
            try:
                p2 = _resolve_path(f2)
                text2 = p2.read_text(encoding='utf-8', errors='replace').splitlines()
                label2 = f2
            except Exception:
                text2 = f2.splitlines()
                label2 = 'text2'
            diff = list(difflib.unified_diff(text1, text2, fromfile=label1, tofile=label2, n=ctx))
            if not diff:
                return 'âœ… ë‘ íŒŒì¼/í…ìŠ¤íŠ¸ê°€ ë™ì¼í•©ë‹ˆë‹¤.'
            return '\n'.join(diff[:300])

        elif name == 'clipboard':
            action = args.get('action', 'list')
            slot = args.get('slot', 'default')
            
            # ìŠ¬ë¡¯ ì´ë¦„ ê¸¸ì´ ì œí•œ (100ì)
            if len(slot) > 100:
                return 'âŒ ìŠ¬ë¡¯ ì´ë¦„ì€ 100ì ì´ë‚´ë¡œ ì œí•œë©ë‹ˆë‹¤'
            
            clip_file = WORKSPACE_DIR / '.clipboard.json'
            
            with _clipboard_lock:  # race condition ë°©ì§€
                try:
                    clips = json.loads(clip_file.read_text()) if clip_file.exists() else {}
                except Exception:
                    clips = {}

                if action == 'copy':
                    content = args.get('content', '')
                    if not content:
                        return 'âŒ contentê°€ í•„ìš”í•©ë‹ˆë‹¤'
                    if len(clips) >= 50 and slot not in clips:
                        return 'âŒ í´ë¦½ë³´ë“œ ìŠ¬ë¡¯ ìµœëŒ€ 50ê°œ ì´ˆê³¼'
                    clips[slot] = {
                        'content': content[:50000],
                        'created': datetime.now(KST).isoformat(),
                        'size': len(content[:50000])  # ì €ì¥ëœ ì‹¤ì œ í¬ê¸°
                    }
                    clip_file.write_text(json.dumps(clips, ensure_ascii=False, indent=2))
                    return f'ğŸ“‹ [{slot}] saved ({len(content[:50000])}ì)'

                elif action == 'paste':
                    if slot not in clips:
                        return f'âŒ ìŠ¬ë¡¯ [{slot}] ì—†ìŒ. ì €ì¥ëœ ìŠ¬ë¡¯: {", ".join(clips.keys()) or "ì—†ìŒ"}'
                    return clips[slot]['content']

                elif action == 'list':
                    if not clips:
                        return 'ğŸ“‹ í´ë¦½ë³´ë“œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.'
                    lines = ['ğŸ“‹ í´ë¦½ë³´ë“œ ëª©ë¡:']
                    for slot_name, data in clips.items():
                        preview = data['content'][:60].replace('\n', ' ')
                        if len(data['content']) > 60:
                            preview += "..."
                        lines.append(f'  [{slot_name}] {data["size"]}ì â€” "{preview}"')
                    return '\n'.join(lines)

                elif action == 'clear':
                    clip_file.write_text('{}')
                    return 'ğŸ—‘ï¸ í´ë¦½ë³´ë“œ ì „ì²´ ì‚­ì œ ì™„ë£Œ'

                return f'âŒ Unknown action: {action}'

        elif name == 'hash_text':
            import hashlib, secrets, string
            action = args.get('action', 'hash')

            if action == 'hash':
                text = args.get('text', '')
                if not text:
                    return 'âŒ textê°€ í•„ìš”í•©ë‹ˆë‹¤'
                algo = args.get('algorithm', 'sha256')
                algos = {'sha256': hashlib.sha256, 'md5': hashlib.md5, 'sha1': hashlib.sha1,
                         'sha512': hashlib.sha512, 'sha384': hashlib.sha384}
                if algo not in algos:
                    return f'âŒ ì§€ì› ì•Œê³ ë¦¬ì¦˜: {", ".join(algos.keys())}'
                h = algos[algo](text.encode('utf-8')).hexdigest()
                return f'ğŸ” {algo.upper()}: {h}'  # ë¯¼ê°ì •ë³´ ë…¸ì¶œ ë°©ì§€

            elif action == 'password':
                length = max(8, min(args.get('length', 16), 128))  # ìµœì†Œ 8ì ê°•ì œ
                charset = string.ascii_letters + string.digits + '!@#$%^&*'
                pw = ''.join(secrets.choice(charset) for _ in range(length))
                return f'ğŸ”‘ ë¹„ë°€ë²ˆí˜¸ ({length}ì): {pw}'

            elif action == 'uuid':
                import uuid as _uuid_mod
                return f'ğŸ†” UUID: {_uuid_mod.uuid4()}'

            elif action == 'token':
                length = min(args.get('length', 32), 256)
                token = secrets.token_hex((length + 1) // 2)[:length]  # í™€ìˆ˜ ê¸¸ì´ ì •í™• ì²˜ë¦¬
                return f'ğŸ« í† í° ({len(token)}ì): {token}'

            return f'âŒ Unknown action: {action}'

        elif name == 'regex_test':
            pattern = args.get('pattern', '')
            text = args.get('text', '')
            action = args.get('action', 'find')
            flags_str = args.get('flags', '')

            # Parse flags
            flags = 0
            if 'i' in flags_str:
                flags |= re.IGNORECASE
            if 'm' in flags_str:
                flags |= re.MULTILINE
            if 's' in flags_str:
                flags |= re.DOTALL

            try:
                compiled = re.compile(pattern, flags)
            except re.error as e:
                return f'âŒ ì •ê·œí‘œí˜„ì‹ ì˜¤ë¥˜: {e}'

            # ReDoS ë°©ì–´ - subprocessë¡œ ê²©ë¦¬ (cross-platform)
            def _run_regex():
                if action == 'match':
                    m = compiled.fullmatch(text)
                    if m:
                        groups = m.groups()
                        gdict = m.groupdict()
                        result = f'âœ… ì „ì²´ ë§¤ì¹­ ì„±ê³µ: "{m.group()}"'
                        if groups:
                            result += f'\nê·¸ë£¹: {groups}'
                        if gdict:
                            result += f'\nëª…ëª… ê·¸ë£¹: {gdict}'
                        return result
                    return 'âŒ ë§¤ì¹­ ì‹¤íŒ¨'

                elif action == 'find':
                    matches = compiled.findall(text)
                    if not matches:
                        return 'âŒ ë§¤ì¹­ ê²°ê³¼ ì—†ìŒ'
                    lines = [f'ğŸ” {len(matches)}ê°œ ë°œê²¬:']
                    for i, m in enumerate(matches[:50], 1):
                        lines.append(f'  {i}. {m}')
                    if len(matches) > 50:
                        lines.append(f'  ... ì™¸ {len(matches)-50}ê°œ')
                    return '\n'.join(lines)

                elif action == 'replace':
                    replacement = args.get('replacement', '')
                    result = compiled.sub(replacement, text)
                    return f'ğŸ”„ ì¹˜í™˜ ê²°ê³¼:\n{result[:5000]}'

                elif action == 'split':
                    parts = compiled.split(text)
                    lines = [f'âœ‚ï¸ {len(parts)}ê°œë¡œ ë¶„í• :']
                    for i, p in enumerate(parts[:50], 1):
                        preview = p[:100]
                        if len(p) > 100:
                            preview += "..."
                        lines.append(f'  {i}. "{preview}"')
                    return '\n'.join(lines)

                return f'âŒ Unknown action: {action}'

            # Run with timeout using threading
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as pool:
                try:
                    future = pool.submit(_run_regex)
                    return future.result(timeout=5)
                except concurrent.futures.TimeoutError:
                    return 'âŒ ì •ê·œì‹ ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼ (5ì´ˆ)'

        elif name == 'cron_manage':
            from .core import _llm_cron
            if not _llm_cron:
                return 'âŒ LLM í¬ë¡  ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'
            action = args.get('action', 'list')
            if action == 'list':
                jobs = _llm_cron.list_jobs()
                if not jobs:
                    return 'â° ë“±ë¡ëœ ìŠ¤ì¼€ì¤„ ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤.'
                lines = ['â° **ìŠ¤ì¼€ì¤„ ì‘ì—… ëª©ë¡:**']
                for j in jobs:
                    status = 'âœ…' if j['enabled'] else 'â¸ï¸'
                    lines.append(f"{status} [{j['id']}] {j['name']} â€” {j['schedule']} (ì‹¤í–‰ {j['run_count']}íšŒ)")
                return '\n'.join(lines)
            elif action == 'add':
                name_ = args.get('name', 'ë¬´ì œ')
                prompt = args.get('prompt', '')
                schedule = args.get('schedule', {})
                if not prompt:
                    return 'âŒ promptê°€ í•„ìš”í•©ë‹ˆë‹¤'
                if not schedule:
                    return 'âŒ scheduleì´ í•„ìš”í•©ë‹ˆë‹¤ (kind: cron/every/at)'
                model = args.get('model')
                job = _llm_cron.add_job(name_, schedule, prompt, model=model)
                return f"â° ìŠ¤ì¼€ì¤„ ì‘ì—… ë“±ë¡: [{job['id']}] {name_}"
            elif action == 'remove':
                job_id = args.get('job_id', '')
                if _llm_cron.remove_job(job_id):
                    return f'â° ì‘ì—… ì‚­ì œ: {job_id}'
                return f'âŒ ì‘ì—… ì—†ìŒ: {job_id}'
            elif action == 'toggle':
                job_id = args.get('job_id', '')
                for j in _llm_cron.jobs:
                    if j['id'] == job_id:
                        j['enabled'] = not j['enabled']
                        _llm_cron.save_jobs()
                        return f"â° {j['name']}: {'í™œì„±í™”' if j['enabled'] else 'ë¹„í™œì„±í™”'}"
                return f'âŒ ì‘ì—… ì—†ìŒ: {job_id}'
            return f'âŒ Unknown action: {action}'

        elif name == 'plugin_manage':
            from .core import PluginLoader
            action = args.get('action', 'list')
            if action == 'list':
                tools = PluginLoader.get_all_tools()
                plugins = PluginLoader._plugins
                if not plugins:
                    return 'ğŸ”Œ ë¡œë“œëœ í”ŒëŸ¬ê·¸ì¸ì´ ì—†ìŠµë‹ˆë‹¤. plugins/ í´ë”ì— .py íŒŒì¼ì„ ì¶”ê°€í•˜ì„¸ìš”.'
                lines = ['ğŸ”Œ **í”ŒëŸ¬ê·¸ì¸ ëª©ë¡:**']
                for name_, info in plugins.items():
                    lines.append(f"  ğŸ“¦ {name_} â€” {len(info['tools'])}ê°œ ë„êµ¬ ({info['path']})")
                    for t in info['tools']:
                        lines.append(f"    ğŸ”§ {t['name']}: {t['description'][:60]}")
                return '\n'.join(lines)
            elif action == 'reload':
                count = PluginLoader.reload()
                return f'ğŸ”Œ í”ŒëŸ¬ê·¸ì¸ ë¦¬ë¡œë“œ: {count}ê°œ ë„êµ¬ ë¡œë“œë¨'
            return f'âŒ Unknown action: {action}'

        elif name == 'browser':
            import asyncio
            from .browser import browser

            def _run_async(coro):
                """Safely run async coroutine from sync context (ThreadPool)."""
                try:
                    loop = asyncio.get_running_loop()
                    # Already in async context â€” use new thread with new loop
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor(1) as pool:
                        return pool.submit(lambda: asyncio.run(coro)).result(timeout=30)
                except RuntimeError:
                    # No running loop â€” safe to use asyncio.run
                    return asyncio.run(coro)

            action = args.get('action', 'status')
            if action == 'status':
                return json.dumps(browser.get_status(), ensure_ascii=False)
            elif action == 'connect':
                ok = _run_async(browser.connect())
                return 'ğŸŒ ë¸Œë¼ìš°ì € ì—°ê²° ì„±ê³µ' if ok else 'âŒ ì—°ê²° ì‹¤íŒ¨. Chrome --remote-debugging-port=9222 í™•ì¸'
            elif action == 'navigate':
                url = args.get('url', '')
                if not url:
                    return 'âŒ urlì´ í•„ìš”í•©ë‹ˆë‹¤'
                result = _run_async(browser.navigate(url))
                return f'ğŸŒ ì´ë™: {url}\n{json.dumps(result, ensure_ascii=False)}'
            elif action == 'text':
                text = _run_async(browser.get_text())
                return text[:5000] if text else '(ë¹ˆ í˜ì´ì§€ ë˜ëŠ” ë¯¸ì—°ê²°)'
            elif action == 'html':
                html = _run_async(browser.get_html())
                return html[:8000] if html else '(ë¹ˆ í˜ì´ì§€ ë˜ëŠ” ë¯¸ì—°ê²°)'
            elif action == 'screenshot':
                b64 = _run_async(browser.screenshot())
                if b64:
                    import base64 as b64mod
                    save_dir = WORKSPACE_DIR / 'uploads'
                    save_dir.mkdir(exist_ok=True)
                    fname = f'screenshot_{int(time.time())}.png'
                    (save_dir / fname).write_bytes(b64mod.b64decode(b64))
                    return f'ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: uploads/{fname} ({len(b64)//1024}KB base64)'
                return 'âŒ ìŠ¤í¬ë¦°ìƒ· ì‹¤íŒ¨ (ë¯¸ì—°ê²°?)'
            elif action == 'evaluate':
                expr = args.get('expression', '')
                if not expr:
                    return 'âŒ expressionì´ í•„ìš”í•©ë‹ˆë‹¤'
                result = _run_async(browser.evaluate(expr))
                return json.dumps(result, ensure_ascii=False, default=str)[:5000]
            elif action == 'click':
                sel = args.get('selector', '')
                ok = _run_async(browser.click(sel))
                return f'âœ… í´ë¦­: {sel}' if ok else f'âŒ ìš”ì†Œ ëª» ì°¾ìŒ: {sel}'
            elif action == 'type':
                sel = args.get('selector', '')
                text = args.get('text', '')
                ok = _run_async(browser.type_text(sel, text))
                return f'âœ… ì…ë ¥: {sel}' if ok else f'âŒ ìš”ì†Œ ëª» ì°¾ìŒ: {sel}'
            elif action == 'tabs':
                tabs = _run_async(browser.get_tabs())
                return json.dumps(tabs, ensure_ascii=False)
            elif action == 'console':
                logs = browser.get_console_logs(limit=30)
                return '\n'.join(logs) if logs else '(ì½˜ì†” ë¡œê·¸ ì—†ìŒ)'
            elif action == 'pdf':
                b64 = _run_async(browser.pdf())
                if b64:
                    import base64 as b64mod
                    save_dir = WORKSPACE_DIR / 'uploads'
                    save_dir.mkdir(exist_ok=True)
                    fname = f'page_{int(time.time())}.pdf'
                    (save_dir / fname).write_bytes(b64mod.b64decode(b64))
                    return f'ğŸ“„ PDF ì €ì¥: uploads/{fname}'
                return 'âŒ PDF ìƒì„± ì‹¤íŒ¨'
            return f'âŒ Unknown action: {action}'

        elif name == 'node_manage':
            from .nodes import node_manager
            action = args.get('action', 'list')
            if action == 'list':
                nodes = node_manager.list_nodes()
                if not nodes:
                    return 'ğŸ“¡ ë“±ë¡ëœ ë…¸ë“œ ì—†ìŒ. node_manage(action="add", name="...", host="...") ë¡œ ì¶”ê°€'
                lines = ['ğŸ“¡ **ë…¸ë“œ ëª©ë¡:**']
                for n in nodes:
                    lines.append(f"  {'ğŸ”—' if n['type']=='ssh' else 'ğŸŒ'} {n['name']} ({n.get('host', n.get('url', '?'))})")
                return '\n'.join(lines)
            elif action == 'add':
                nname = args.get('name', '')
                ntype = args.get('type', 'ssh')
                if not nname:
                    return 'âŒ nameì´ í•„ìš”í•©ë‹ˆë‹¤'
                if ntype == 'ssh':
                    host = args.get('host', '')
                    if not host:
                        return 'âŒ hostê°€ í•„ìš”í•©ë‹ˆë‹¤'
                    node_manager.add_ssh_node(nname, host, user=args.get('user', 'root'),
                                              port=args.get('port', 22), key=args.get('key'))
                    return f'ğŸ“¡ SSH ë…¸ë“œ ì¶”ê°€: {nname}'
                elif ntype == 'http':
                    url = args.get('url', '')
                    if not url:
                        return 'âŒ urlì´ í•„ìš”í•©ë‹ˆë‹¤'
                    node_manager.add_http_node(nname, url)
                    return f'ğŸ“¡ HTTP ë…¸ë“œ ì¶”ê°€: {nname}'
                return f'âŒ ì•Œ ìˆ˜ ì—†ëŠ” type: {ntype}'
            elif action == 'remove':
                nname = args.get('name', '')
                if node_manager.remove_node(nname):
                    return f'ğŸ“¡ ë…¸ë“œ ì œê±°: {nname}'
                return f'âŒ ë…¸ë“œ ì—†ìŒ: {nname}'
            elif action == 'run':
                nname = args.get('name', '')
                cmd = args.get('command', '')
                if not nname or not cmd:
                    return 'âŒ nameê³¼ commandê°€ í•„ìš”í•©ë‹ˆë‹¤'
                result = node_manager.run_on(nname, cmd)
                return json.dumps(result, ensure_ascii=False)[:5000]
            elif action == 'status':
                nname = args.get('name')
                if nname:
                    node = node_manager.get_node(nname)
                    if not node:
                        return f'âŒ ë…¸ë“œ ì—†ìŒ: {nname}'
                    return json.dumps(node.status(), ensure_ascii=False)[:3000]
                return json.dumps(node_manager.status_all(), ensure_ascii=False)[:5000]
            elif action == 'wake':
                mac = args.get('mac', '')
                if not mac:
                    return 'âŒ macì´ í•„ìš”í•©ë‹ˆë‹¤'
                result = node_manager.wake_on_lan(mac)
                return json.dumps(result, ensure_ascii=False)
            return f'âŒ Unknown action: {action}'

        elif name == 'health_check':
            from .stability import health_monitor
            action = args.get('action', 'check')
            if action == 'check':
                report = health_monitor.check_health()
                lines = [f"ğŸ¥ **ì‹œìŠ¤í…œ ìƒíƒœ: {report['status'].upper()}**",
                         f"â±ï¸ ê°€ë™ì‹œê°„: {report['uptime_human']}"]
                sys_info = report.get('system', {})
                if sys_info.get('memory_mb'):
                    lines.append(f"ğŸ’¾ ë©”ëª¨ë¦¬: {sys_info['memory_mb']}MB")
                if sys_info.get('disk_free_mb'):
                    lines.append(f"ğŸ’¿ ë””ìŠ¤í¬: {sys_info['disk_free_mb']}MB ì—¬ìœ  ({sys_info.get('disk_pct',0)}% ì‚¬ìš©)")
                lines.append(f"ğŸ§µ ìŠ¤ë ˆë“œ: {sys_info.get('threads', '?')}")
                lines.append("")
                for comp, status in report['components'].items():
                    icon = 'âœ…' if status.get('status') == 'ok' else 'âš ï¸' if status.get('status') != 'error' else 'âŒ'
                    lines.append(f"  {icon} {comp}: {status.get('status', '?')}")
                return '\n'.join(lines)
            elif action == 'selftest':
                result = health_monitor.startup_selftest()
                lines = [f"ğŸ§ª **ì…€í”„í…ŒìŠ¤íŠ¸: {result['passed']}/{result['total']}**"]
                for mod, status in result['modules'].items():
                    icon = 'âœ…' if status == 'ok' else 'âŒ'
                    lines.append(f"  {icon} {mod}: {status}")
                return '\n'.join(lines)
            elif action == 'recover':
                import asyncio
                try:
                    loop = asyncio.get_running_loop()
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor(1) as pool:
                        recovered = pool.submit(lambda: asyncio.run(health_monitor.auto_recover())).result(timeout=30)
                except RuntimeError:
                    recovered = asyncio.run(health_monitor.auto_recover())
                if recovered:
                    return f'ğŸ”§ ë³µêµ¬ Finished: {", ".join(recovered)}'
                return 'ğŸ”§ ë³µêµ¬í•  ì»´í¬ë„ŒíŠ¸ ì—†ìŒ (ëª¨ë‘ ì •ìƒ)'
            return f'âŒ Unknown action: {action}'

        elif name == 'mcp_manage':
            from .mcp import mcp_manager
            action = args.get('action', 'list')
            if action == 'list':
                servers = mcp_manager.list_servers()
                if not servers:
                    return 'ğŸ”Œ ì—°ê²°ëœ MCP ì„œë²„ ì—†ìŒ. mcp_manage(action="add", name="...", command="...") ë¡œ ì¶”ê°€í•˜ì„¸ìš”.'
                lines = ['ğŸ”Œ **MCP ì„œë²„ ëª©ë¡:**']
                for s in servers:
                    status = 'ğŸŸ¢' if s['connected'] else 'ğŸ”´'
                    lines.append(f"  {status} {s['name']} â€” {s['tools']}ê°œ ë„êµ¬ ({' '.join(s['command'])})")
                return '\n'.join(lines)
            elif action == 'add':
                sname = args.get('name', '')
                cmd_str = args.get('command', '')
                if not sname or not cmd_str:
                    return 'âŒ nameê³¼ commandê°€ í•„ìš”í•©ë‹ˆë‹¤'
                cmd_list = cmd_str.split()
                env = args.get('env', {})
                ok = mcp_manager.add_server(sname, cmd_list, env=env)
                if ok:
                    mcp_manager.save_config()
                    tools_count = len([t for t in mcp_manager.get_all_tools() if t.get('_mcp_server') == sname])
                    return f'ğŸ”Œ MCP ì„œë²„ ì¶”ê°€ ì„±ê³µ: {sname} ({tools_count}ê°œ ë„êµ¬)'
                return f'âŒ MCP ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {sname}'
            elif action == 'remove':
                sname = args.get('name', '')
                mcp_manager.remove_server(sname)
                mcp_manager.save_config()
                return f'ğŸ”Œ MCP ì„œë²„ ì œê±°: {sname}'
            elif action == 'tools':
                all_mcp = mcp_manager.get_all_tools()
                if not all_mcp:
                    return 'ğŸ”Œ MCP ë„êµ¬ ì—†ìŒ (ì„œë²„ê°€ ì—°ê²°ë˜ì–´ ìˆì§€ ì•ŠìŒ)'
                lines = [f'ğŸ”Œ **MCP ë„êµ¬ ({len(all_mcp)}ê°œ):**']
                for t in all_mcp:
                    lines.append(f"  ğŸ”§ {t['name']}: {t['description'][:80]}")
                return '\n'.join(lines)
            return f'âŒ Unknown action: {action}'

        elif name == 'rag_search':
            from .rag import rag_engine
            query = args.get('query', '')
            if not query:
                return 'âŒ queryê°€ í•„ìš”í•©ë‹ˆë‹¤'
            max_results = args.get('max_results', 5)
            results = rag_engine.search(query, max_results=max_results)
            if not results:
                return f'ğŸ” "{query}" ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ'
            lines = [f'ğŸ” **"{query}" ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê±´):**']
            for r in results:
                lines.append(f"\nğŸ“„ **{r['source']}** (L{r['line']}, score: {r['score']})")
                lines.append(r['text'][:300])
            stats = rag_engine.get_stats()
            lines.append(f"\nğŸ“Š ì¸ë±ìŠ¤: {stats['total_chunks']}ì²­í¬, {stats['unique_terms']}ë‹¨ì–´, {stats['db_size_kb']}KB")
            return '\n'.join(lines)

        else:
            # Try plugin tools as fallback
            from .core import PluginLoader
            result = PluginLoader.execute(name, args)
            if result is not None:
                return result
            # Try MCP tools as last fallback
            if name.startswith('mcp_'):
                from .mcp import mcp_manager
                mcp_result = mcp_manager.call_tool(name, args)
                if mcp_result is not None:
                    return mcp_result
            return f'âŒ ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {name}'

    except PermissionError as e:
        return f'âŒ ê¶Œí•œ ê±°ë¶€: {e}'
    except Exception as e:
        log.error(f"Tool error ({name}): {e}")
        return f'âŒ ë„êµ¬ ì˜¤ë¥˜: {str(e)[:200]}'
